{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import pickle\n",
    "import random as rn\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from importlib import reload\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.fasttext import FastText\n",
    "from IPython.display import display\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, ndcg_score, \\\n",
    "        label_ranking_average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import data\n",
    "import models\n",
    "import preprocessing\n",
    "\n",
    "seed = 42\n",
    "sns.set()\n",
    "\n",
    "def reset_seed():\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "    np.random.seed(seed)\n",
    "    rn.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose notebook version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version = \"tokenized_cased\"\n",
    "version = \"tokenized_no_sw_no_punct\"\n",
    "# version = \"tokenized_lemmatized_no_sw_no_punct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Extracting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299773,)\n",
      "(299773, 126)\n",
      "Toronto stocks end higher after volatile session. CHANGE\t\t\t\t    CHANGE TSE\t  5900.37    +50.15   HI 5900.37\t    LO  5840.29 DJI\t  6611.05    +27.57   GOLD (LONDON)   US$350.00 +1.90 FTSE100    4248.10    -64.80   GOLD (NY-COMEX) US$354.80 +0.70 NIKKEI    17869.59   -133.81   LME CASH NICKEL US$7659   +99.0 CANDLR\t1.3883\t\t LME CASH ALUM   US$1602.0  -4.0 CAN 30-YR   107.41     -0.15   BRENT CRUDE     US$19.09  -0.27 --------------------MARKET COMMENT---------------------------- * Toronto stocks ended higher on Tuesday, buoyed by strength in golds and banking * Computer problems due to heavy trading in Bre-X Minerals hampered session * 84 million shares traded Toronto's key stock index ended higher on Tuesday as the saga of Bre-X Minerals Ltd and its Indonesian gold find continued to dominate Canada's biggest stock market. The TSE 300 Index climbed 50.15 points to close at 5900.37 in heavy turnover of 84.07 million shares worth C$1.4 billion. But the overall market was mixed with declining issues narrowly outpacing advances 476 to 464. 298 issues were flat. Frantic trading in Bre-X collapsed the TSE's computer trading system earlier in the day, forcing the exchange to halt trading in the stock before the market closed. Shares in the Calgary-based gold prospector were halted for a statement by the company this morning. When it resumed, a whopping 7.7 million shares changed hands in the first 22 minutes of trading before the system crashed. Bre-X closed up 1.35 at 3.85. It was the first time Bre-X traded since investors lopped nearly C$3 billion off its stock market value last Thursday. TSE officials said the trading problems were due to old technology which will be replaced. On the Montreal Exchange, Bre-X closed up 0.81 at 3.50 on 9.8 million shares. Analysts predicted more volatility for Bre-X shares this week. \"The question of what Bre-X will release over the next few days will be important to the market,\" said Josef Schachter, of Schachter Asset Management Inc. The gold sector rose nearly 136 points, leading 12 of 14 sub-indices higher. Other strong groups included financial services, consumer products, energy and transportation. The TSE posted minor losses in forestry and real estate. --- HOT STOCKS --- * Among bank shares, Bank of Nova Scotia rose 0.65 to 51.50 on 2.1 million shares, while Canadian Imperial Bank of Commerce added 0.50 to 31.80 on 2.1 million shares. ((Reuters Toronto Bureau (416) 941-8100))\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# data.extract_data(extraction_dir=\"train\",\n",
    "#                   data_dir=\"data\",\n",
    "#                   data_zip_name=\"reuters-training-corpus.zip\")\n",
    "\n",
    "train_df = pd.read_pickle(\"train/data.pkl\")\n",
    "\n",
    "# train_df = data.get_docs_labels(\"train/REUTERS_CORPUS_2\")\n",
    "# train_df.to_pickle(\"train/data.pkl\")\n",
    "\n",
    "train_docs = train_df[\"doc\"].values\n",
    "n_train = train_docs.shape[0]\n",
    "train_labels = np.array(train_df[\"labels\"].tolist())\n",
    "n_labels = len(data.CODEMAP)\n",
    "\n",
    "# extract test_docs here\n",
    "\n",
    "print(train_docs.shape)\n",
    "print(train_labels.shape)\n",
    "print(train_docs[2])\n",
    "print(train_labels[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocessing the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toronto stocks end higher volatile session change change tse 5900.37 +50.15 hi 5900.37 lo 5840.29 dji 6611.05 +27.57 gold london us$ 350.00 +1.90 ftse100 4248.10 -64.80 gold ny comex us$ 354.80 +0.70 nikkei 17869.59 -133.81 lme cash nickel us$ 7659 +99.0 candlr 1.3883 lme cash alum us$ 1602.0 -4.0 30-yr 107.41 -0.15 brent crude us$ 19.09 -0.27 --------------------market comment---------------------------- toronto stocks ended higher tuesday buoyed strength golds banking computer problems heavy trading bre x minerals hampered session 84 million shares traded toronto key stock index ended higher tuesday saga bre x minerals ltd indonesian gold find continued dominate canada biggest stock market tse 300 index climbed 50.15 points close 5900.37 heavy turnover 84.07 million shares worth c$ 1.4 billion overall market mixed declining issues narrowly outpacing advances 476 464 298 issues flat frantic trading bre x collapsed tse computer trading system earlier day forcing exchange halt trading stock market closed shares calgary based gold prospector halted statement company morning resumed whopping 7.7 million shares changed hands 22 minutes trading system crashed bre x closed 1.35 3.85 time bre x traded investors lopped nearly c$ 3 billion stock market value thursday tse officials said trading problems old technology replaced montreal exchange bre x closed 0.81 3.50 9.8 million shares analysts predicted volatility bre x shares week question bre x release days important market said josef schachter schachter asset management inc. gold sector rose nearly 136 points leading 12 14 sub indices higher strong groups included financial services consumer products energy transportation tse posted minor losses forestry real estate hot stocks bank shares bank nova scotia rose 0.65 51.50 2.1 million shares canadian imperial bank commerce added 0.50 31.80 2.1 million shares reuters toronto bureau 416 941 8100\n"
     ]
    }
   ],
   "source": [
    "path_to_preprocessed_train_docs = f\"train/preprocessed_docs_{version}.pkl\"\n",
    "\n",
    "try:\n",
    "    with open(path_to_preprocessed_train_docs, \"rb\") as f:\n",
    "        preprocessed_train_docs = pickle.load(f)\n",
    "except:\n",
    "    preprocessed_train_docs = preprocessing.preprocess_corpus(train_docs)\n",
    "    with open(path_to_preprocessed_train_docs, \"wb\") as f:\n",
    "        pickle.dump(preprocessed_train_docs, f)\n",
    "\n",
    "print(preprocessed_train_docs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_preprocessed_test_docs = f\"test/preprocessed_docs_{version}.pkl\"\n",
    "\n",
    "# try:\n",
    "#     with open(path_to_preprocessed_test_docs, \"rb\") as f:\n",
    "#         preprocessed_test_docs = pickle.load(f)\n",
    "# except:\n",
    "#     preprocessed_test_docs = preprocessing.preprocess_corpus(test_docs)\n",
    "#     with open(path_to_preprocessed_test_docs, \"wb\") as f:\n",
    "#         pickle.dump(preprocessed_test_docs, f)\n",
    "\n",
    "# print(preprocessed_test_docs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing the documents as token index sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = preprocessed_train_docs # add preprocessed_test_docs\n",
    "n_vocabulary = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660067\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=n_vocabulary, filters=\"\", lower=False)\n",
    "tokenizer.fit_on_texts(docs)\n",
    "word_idx = tokenizer.word_index\n",
    "if n_vocabulary is None:\n",
    "    n_vocabulary = len(word_idx) + 1 # use index 0 for padding\n",
    "\n",
    "print(n_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "(299773, 768)\n",
      "[  1684    106     61     67   2237    457    224    224   7987 197878\n",
      " 337939   5079 197878   6678 337940  25315 150898 241565    198    105\n",
      "    456  19090 108710  48033 337941 337942    198   2806   2603    456\n",
      " 197879  57875   2451 337943 169476   1416    215   1964    456 337944\n",
      " 337945  20915 169477   1416    215  18380    456 337946  12825   9380\n",
      " 101955  29604    910    397    456  35224  40017  28348  31540   1684\n",
      "    106     80     67     23   4829    858   8961    507    835    541\n",
      "    620     77   2818   1579   4257   7988    457   3663      4     13\n",
      "    304   1684    283     44     59     80     67     23   8635   2818\n",
      "   1579   4257    113   1492    198    975    454   6459    452    562]\n"
     ]
    }
   ],
   "source": [
    "n_sequence = 768\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(docs)\n",
    "if n_sequence is None:\n",
    "    n_sequence = max([len(s) for s in sequences])\n",
    "sequence_lengths = [min(len(s), n_sequence) for s in sequences]\n",
    "sequences = pad_sequences(sequences,\n",
    "                          maxlen=n_sequence,\n",
    "                          padding=\"post\",\n",
    "                          truncating=\"post\")\n",
    "\n",
    "print(n_sequence)\n",
    "print(sequences.shape)\n",
    "print(sequences[2][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_lengths = [len(doc.split()) for doc in docs]\n",
    "\n",
    "sns.distplot(doc_lengths,\n",
    "             bins=np.arange(0, 2500, 25),\n",
    "             kde=False,\n",
    "             label=\"documents\")\n",
    "sns.distplot(sequence_lengths,\n",
    "             bins=np.arange(0, 2500, 25),\n",
    "             kde=False,\n",
    "             label=\"sequences\")\n",
    "total_word_coverage = np.round(np.sum(sequence_lengths) / np.sum(doc_lengths), 3)\n",
    "plt.title(f\"n_vocabulary={n_vocabulary}, n_sequence={n_sequence},\\n\"\n",
    "          f\"total_word_coverage={total_word_coverage}\")\n",
    "plt.xlim(0, 1550)\n",
    "plt.xlabel(\"length\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_embedding = 300 # 300 required by pretrained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660066\n",
      "['said', '$', 'percent', 'million', 'year', 'market', 'new', 'bank', 'n', 'company', 'government', 'u.s.', 'shares', 'billion', '1997', 'june', '1', 'newsroom', 'net', 'week', 'share', 'pct', 'tuesday', '1996', 'group', 'wednesday', 'july', 'sales', 'expected', 'prices', 'thursday', 'monday', 'trade', 'friday', '2', 'price', '=', 'state', 'vs', 'yen', 'told', 'income', 'rate', 'stock', 'interest', 'minister', 'month', 'oil', 'quarter', 'april', 'president', 'day', 'time', '10', 'dollar', 'high', 'months', 'march', 'index', 'foreign', 'end', 'points', '30', 'years', 'rates', 'total', 'higher', 'central', 'european', 'people', 'profit', 'f', 'tax', 'loss', 'second', 'international', 'trading', 'cents', 'traders', 'ended', '3', 'business', 'added', 'rose', 'lower', 'growth', 'exchange', 'world', 'economic', 'financial', 'official', 'close', 'analysts', '20', 'statement', 'tonnes', 'reuters', 'news', 'results', 'companies']\n"
     ]
    }
   ],
   "source": [
    "reset_seed()\n",
    "\n",
    "# ft_path = f\"data/fasttext_{version}.model\"\n",
    "ft_path = f\"train/fasttext_{version}.model\"\n",
    "\n",
    "try:\n",
    "    ft = FastText.load(ft_path)\n",
    "except:\n",
    "    ft = FastText(sentences=[doc.split() for doc in docs], size=n_embedding,\n",
    "                  min_count=1, workers=cpu_count(), seed=seed)\n",
    "    ft.save(ft_path)\n",
    "\n",
    "print(len(list(ft.wv.vocab)))\n",
    "print(ft.wv.index2entity[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660066\n",
      "['said', '$', 'percent', 'million', 'year', 'market', 'new', 'bank', 'n', 'company', 'government', 'u.s.', 'shares', 'billion', '1997', 'june', '1', 'newsroom', 'net', 'week', 'share', 'pct', 'tuesday', '1996', 'group', 'wednesday', 'july', 'sales', 'expected', 'prices', 'thursday', 'monday', 'trade', 'friday', '2', 'price', '=', 'state', 'vs', 'yen', 'told', 'income', 'rate', 'stock', 'interest', 'minister', 'month', 'oil', 'quarter', 'april', 'president', 'day', 'time', '10', 'dollar', 'high', 'months', 'march', 'index', 'foreign', 'end', 'points', '30', 'years', 'rates', 'total', 'higher', 'central', 'european', 'people', 'profit', 'f', 'tax', 'loss', 'second', 'international', 'trading', 'cents', 'traders', 'ended', '3', 'business', 'added', 'rose', 'lower', 'growth', 'exchange', 'world', 'economic', 'financial', 'official', 'close', 'analysts', '20', 'statement', 'tonnes', 'reuters', 'news', 'results', 'companies']\n"
     ]
    }
   ],
   "source": [
    "reset_seed()\n",
    "\n",
    "# w2v_path = f\"data/w2v_{version}.model\"\n",
    "w2v_path = f\"train/w2v_{version}.model\"\n",
    "\n",
    "try:\n",
    "    w2v = Word2Vec.load(w2v_path)\n",
    "except:\n",
    "    w2v = Word2Vec(sentences=[doc.split() for doc in docs], size=n_embedding,\n",
    "                   min_count=1, workers=cpu_count(), seed=seed)\n",
    "    w2v.save(w2v_path)\n",
    "\n",
    "print(len(list(w2v.wv.vocab)))\n",
    "print(w2v.wv.index2entity[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(fname, skip_first):\n",
    "    embedding_idx = {}\n",
    "    with open(fname, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i == 0 and skip_first:\n",
    "                continue\n",
    "            vals = line.rstrip().split()\n",
    "            token = \"\".join(vals[:-300])\n",
    "            embedding = np.array(vals[-300:], dtype=np.float32)\n",
    "            embedding_idx[token] = embedding\n",
    "    return embedding_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', 'the', '.', 'and', 'to', 'of', 'a', 'in', 'is', 'for', 'that', 'I', 'it', 'on', 'with', ')', ':', '\"', '(', 'The', 'you', 'was', 'are', 'or', 'this', 'as', 'have', 'at', 'from', '!', \"'s\", 'but', 'by', 'not', '?', 'your', 'all', '/', 'be', 'we', 'my', 'one', '-', 'will', 'they', 'so', 'which', '”', '“', 'has', '...', 'just', 'he', 'their', 'can', 'about', 'his', 'our', ';', 'when', 'more', 'had', 'do', 'some', 'time', 'like', 'also', 'there', 'them', 'get', 'what', 'out', \"'\", 'me', 'her', 'an', 'were', 'This', 'It', 'up', 'would', 'if', 'who', 'new', 'only', 'A', '–', 'people', 'any', 'We', 'make', 'other', 'In', 'then', 'its', 'use', 'said', 'now', 'no', 'first']\n"
     ]
    }
   ],
   "source": [
    "ft_pretrained = load_embeddings(\"data/crawl-300d-2M.vec\", skip_first=True)\n",
    "\n",
    "token_iter = iter(ft_pretrained)\n",
    "print([next(token_iter) for i in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', 'the', '.', 'and', 'to', 'of', 'a', 'in', '\"', 'is', 'for', ':', 'i', ')', 'that', '(', 'you', 'it', 'on', '-', 'with', \"'s\", 'this', 'by', 'are', 'at', 'as', 'be', 'from', 'have', 'was', 'or', 'your', 'not', '...', 'we', '!', 'but', '?', 'all', 'will', 'an', 'my', 'can', 'they', \"n't\", 'do', 'he', 'more', 'if', 'one', 'has', '|', 'so', 'about', 'new', 'what', 'his', 'there', 'up', 'out', ';', 'their', 'our', \"'\", 'like', 'when', '$', 'just', 'time', '&', 'me', 'which', 'who', 'no', 'would', '/', '1', 'some', 'get', '[', ']', 'also', 'other', 'how', 'may', 'had', 'am', 'been', '2', 'her', 'were', 'them', 'people', 'she', 'any', 'now', 'only', 'pm', 'first']\n"
     ]
    }
   ],
   "source": [
    "if version == \"tokenized_cased\":\n",
    "    glove_pretrained = load_embeddings(\"data/glove.840B.300d.txt\", skip_first=False)\n",
    "else:\n",
    "    glove_pretrained = load_embeddings(\"data/glove.42B.300d.txt\", skip_first=False)\n",
    "    \n",
    "token_iter = iter(glove_pretrained)\n",
    "print([next(token_iter) for i in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_embedding_matrix(embedding_model):\n",
    "    embedding_matrix = np.zeros((n_vocabulary, n_embedding))\n",
    "    unknown_token_count = 0\n",
    "    for token, i in word_idx.items():\n",
    "        if i >= n_vocabulary:\n",
    "            continue\n",
    "        if token in embedding_model:\n",
    "            embedding_matrix[i] = embedding_model[token]\n",
    "        else:\n",
    "            unknown_token_count += 1\n",
    "\n",
    "    print(unknown_token_count)\n",
    "    print(embedding_matrix.shape)\n",
    "    print(embedding_matrix[1][:20])\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(660067, 300)\n",
      "[-3.71252584  3.69840598 -5.05772781  5.39064503  3.97756577  1.23077226\n",
      "  4.78732109 -2.40194106  2.73621893  3.20716929 -0.37027493  0.71109104\n",
      "  0.9743709  -0.35793254  0.50945872  2.20875049  0.26744497  1.71014547\n",
      " -0.14868788 -0.01606547]\n"
     ]
    }
   ],
   "source": [
    "ft_embedding_matrix = create_embedding_matrix(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(660067, 300)\n",
      "[ 1.23901904  0.13068858 -1.80657494 -1.38192809 -1.59526336 -0.51683563\n",
      " -0.33008185  0.52108902  0.50567162  1.76178634 -0.65225005 -2.21308708\n",
      "  0.54367632  0.73135346  2.02280545 -0.58001477 -0.11211004  2.56782937\n",
      " -0.20630927 -0.42374206]\n"
     ]
    }
   ],
   "source": [
    "w2v_embedding_matrix = create_embedding_matrix(w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500890\n",
      "(660067, 300)\n",
      "[ 0.28940001 -0.18539999 -0.40180001 -0.16249999 -0.1032      0.0563\n",
      "  0.2384     -0.1227     -0.50029999  0.1684     -0.17039999  0.31240001\n",
      "  0.0529     -0.0063      0.17209999  0.1389      0.0145     -0.20550001\n",
      "  0.0601      0.014     ]\n"
     ]
    }
   ],
   "source": [
    "ft_pretrained_embedding_matrix = create_embedding_matrix(ft_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410497\n",
      "(660067, 300)\n",
      "[-0.37941     0.080833   -0.10343     0.29754001 -0.13299    -0.64884001\n",
      " -3.35279989  1.16410005 -0.24668001 -0.31876001 -0.36869001  0.46322\n",
      " -0.14533    -0.51498997 -0.14117999 -0.11483     0.45131999 -0.49171999\n",
      " -0.20461001  0.778     ]\n"
     ]
    }
   ],
   "source": [
    "glove_pretrained_embedding_matrix = create_embedding_matrix(glove_pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = None\n",
    "x_train, y_train = shuffle(sequences[:n_train],\n",
    "                           train_labels,\n",
    "                           random_state=seed,\n",
    "                           n_samples=n_samples)\n",
    "# x_test = sequences[n_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-evaluating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_evaluate(model_initializer, batch_size=256, model_params={}):\n",
    "    model_initializer(n_vocabulary, n_embedding, n_sequence, n_labels,\n",
    "                      **model_params).summary()\n",
    "\n",
    "    cv_scores = []\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=5, random_state=seed)\n",
    "    for train, val in mskf.split(x_train, y_train):\n",
    "        model = model_initializer(n_vocabulary, n_embedding, n_sequence, n_labels,\n",
    "                                  **model_params)\n",
    "        es = EarlyStopping(patience=10, verbose=1, restore_best_weights=True)\n",
    "        history = model.fit(x_train[train],\n",
    "                            y_train[train],\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=100,\n",
    "                            verbose=1,\n",
    "                            validation_data=(x_train[val], y_train[val]),\n",
    "                            callbacks=[es])\n",
    "\n",
    "        y_val_pred_prob = model.predict(x_train[val], batch_size=batch_size, verbose=1)\n",
    "        y_val_pred = np.round(y_val_pred_prob)\n",
    "\n",
    "        scores = {}\n",
    "        scores[\"accuracy\"] = accuracy_score(y_train[val], y_val_pred)\n",
    "        scores[\"F1 (macro)\"] = f1_score(y_train[val], y_val_pred, average=\"macro\")\n",
    "        scores[\"F1 (micro)\"] = f1_score(y_train[val], y_val_pred, average=\"micro\")\n",
    "        scores[\"LRAP\"] = label_ranking_average_precision_score(y_train[val],\n",
    "                                                               y_val_pred_prob)\n",
    "        scores[\"NDCG\"] = ndcg_score(y_train[val], y_val_pred_prob)\n",
    "        scores[\"timestamp\"] = round(datetime.timestamp(datetime.now()))\n",
    "        cv_scores.append(scores)\n",
    "        print(scores)\n",
    "        \n",
    "#         np.savetxt(f\"val_results/{model_initializer.__name__}_{version}_\" +\n",
    "#                    f\"{scores['timestamp']}_\" +\n",
    "#                    f\"{np.round(scores['F1 (micro)'], 6)}.txt\", y_val_pred, fmt=\"%d\")\n",
    "\n",
    "    cv_scores_df = pd.DataFrame(cv_scores)\n",
    "    display(cv_scores_df)\n",
    "    print(cv_scores_df.drop(\"timestamp\", axis=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 768, 300)          198020100 \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 767, 400)          240400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 767, 400)          1600      \n",
      "_________________________________________________________________\n",
      "re_lu_30 (ReLU)              (None, 767, 400)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 383, 400)          0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 383, 400)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 382, 500)          400500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 382, 500)          2000      \n",
      "_________________________________________________________________\n",
      "re_lu_31 (ReLU)              (None, 382, 500)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 191, 500)          0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 191, 500)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_13 (Bidirectio (None, 512)               1550336   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 126)               64638     \n",
      "=================================================================\n",
      "Total params: 200,279,574\n",
      "Trainable params: 2,257,674\n",
      "Non-trainable params: 198,021,900\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 71s 76ms/step - loss: 0.0433 - val_loss: 0.0225\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0204 - val_loss: 0.0185\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 67s 72ms/step - loss: 0.0178 - val_loss: 0.0173\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 67s 72ms/step - loss: 0.0165 - val_loss: 0.0165\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0157 - val_loss: 0.0161\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0151 - val_loss: 0.0160\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0146 - val_loss: 0.0156\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 67s 72ms/step - loss: 0.0141 - val_loss: 0.0155\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 67s 72ms/step - loss: 0.0138 - val_loss: 0.0154\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0134 - val_loss: 0.0153\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0132 - val_loss: 0.0154\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0129 - val_loss: 0.0152\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0126 - val_loss: 0.0154\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0124 - val_loss: 0.0153\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0122 - val_loss: 0.0155\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0120 - val_loss: 0.0154\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0118Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 69s 73ms/step - loss: 0.0118 - val_loss: 0.0155\n",
      "Epoch 00017: early stopping\n",
      "235/235 [==============================] - 5s 22ms/step\n",
      "{'accuracy': 0.6876886894734209, 'F1 (macro)': 0.5999249015486136, 'F1 (micro)': 0.8916087246404418, 'LRAP': 0.9588675490340012, 'NDCG': 0.9756602994541531}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 71s 75ms/step - loss: 0.0415 - val_loss: 0.0220\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 67s 72ms/step - loss: 0.0203 - val_loss: 0.0190\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 67s 72ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0165 - val_loss: 0.0163\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0157 - val_loss: 0.0159\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0151 - val_loss: 0.0157\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0146 - val_loss: 0.0156\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 67s 72ms/step - loss: 0.0141 - val_loss: 0.0155\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0137 - val_loss: 0.0152\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0134 - val_loss: 0.0151\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0131 - val_loss: 0.0154\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 67s 72ms/step - loss: 0.0129 - val_loss: 0.0151\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0126 - val_loss: 0.0153\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0124 - val_loss: 0.0152\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0121 - val_loss: 0.0154\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0120 - val_loss: 0.0153\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0118Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 68s 73ms/step - loss: 0.0118 - val_loss: 0.0155\n",
      "Epoch 00017: early stopping\n",
      "235/235 [==============================] - 5s 22ms/step\n",
      "{'accuracy': 0.683885710473204, 'F1 (macro)': 0.59073924610004, 'F1 (micro)': 0.8914903744446795, 'LRAP': 0.9592540105866715, 'NDCG': 0.9751416332744892}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 71s 75ms/step - loss: 0.0422 - val_loss: 0.0226\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 67s 72ms/step - loss: 0.0206 - val_loss: 0.0187\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0180 - val_loss: 0.0172\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 67s 72ms/step - loss: 0.0167 - val_loss: 0.0164\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 67s 72ms/step - loss: 0.0159 - val_loss: 0.0164\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 67s 72ms/step - loss: 0.0152 - val_loss: 0.0158\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0147 - val_loss: 0.0156\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 67s 72ms/step - loss: 0.0142 - val_loss: 0.0152\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0139 - val_loss: 0.0154\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 67s 72ms/step - loss: 0.0135 - val_loss: 0.0152\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0132 - val_loss: 0.0154\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0130 - val_loss: 0.0153\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0127 - val_loss: 0.0153\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 66s 71ms/step - loss: 0.0124 - val_loss: 0.0153\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0122Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 68s 73ms/step - loss: 0.0122 - val_loss: 0.0153\n",
      "Epoch 00015: early stopping\n",
      "235/235 [==============================] - 5s 22ms/step\n",
      "{'accuracy': 0.6892313337002385, 'F1 (macro)': 0.5769756954251424, 'F1 (micro)': 0.8908249996008325, 'LRAP': 0.9574913607734222, 'NDCG': 0.977724617969515}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 71s 75ms/step - loss: 0.0421 - val_loss: 0.0227\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0206 - val_loss: 0.0184\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0179 - val_loss: 0.0174\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0166 - val_loss: 0.0165\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0158 - val_loss: 0.0162\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0151 - val_loss: 0.0158\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0146 - val_loss: 0.0158\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0142 - val_loss: 0.0158\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0138 - val_loss: 0.0156\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0135 - val_loss: 0.0154\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0132 - val_loss: 0.0156\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 71s 76ms/step - loss: 0.0129 - val_loss: 0.0155\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0126 - val_loss: 0.0154\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0124 - val_loss: 0.0155\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0118 - val_loss: 0.0156\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0116Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 69s 73ms/step - loss: 0.0116 - val_loss: 0.0158\n",
      "Epoch 00018: early stopping\n",
      "235/235 [==============================] - 5s 22ms/step\n",
      "{'accuracy': 0.6837355928810902, 'F1 (macro)': 0.5908180714279215, 'F1 (micro)': 0.8906634977223213, 'LRAP': 0.9587391384866483, 'NDCG': 0.9754969428738423}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 74s 79ms/step - loss: 0.0414 - val_loss: 0.0220\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 67s 72ms/step - loss: 0.0203 - val_loss: 0.0184\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 67s 72ms/step - loss: 0.0178 - val_loss: 0.0170\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 67s 72ms/step - loss: 0.0165 - val_loss: 0.0165\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 67s 72ms/step - loss: 0.0157 - val_loss: 0.0161\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 67s 72ms/step - loss: 0.0151 - val_loss: 0.0161\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 67s 72ms/step - loss: 0.0146 - val_loss: 0.0155\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0142 - val_loss: 0.0155\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0138 - val_loss: 0.0157\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0134 - val_loss: 0.0154\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 67s 72ms/step - loss: 0.0131 - val_loss: 0.0156\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0128 - val_loss: 0.0155\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0126 - val_loss: 0.0155\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0124 - val_loss: 0.0154\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0122Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 69s 73ms/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 00015: early stopping\n",
      "235/235 [==============================] - 5s 22ms/step\n",
      "{'accuracy': 0.6859206378329692, 'F1 (macro)': 0.5885870434270981, 'F1 (micro)': 0.890565897501918, 'LRAP': 0.9573505346267526, 'NDCG': 0.9757838932387786}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1 (macro)</th>\n",
       "      <th>F1 (micro)</th>\n",
       "      <th>LRAP</th>\n",
       "      <th>NDCG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.687689</td>\n",
       "      <td>0.599925</td>\n",
       "      <td>0.891609</td>\n",
       "      <td>0.958868</td>\n",
       "      <td>0.975660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.683886</td>\n",
       "      <td>0.590739</td>\n",
       "      <td>0.891490</td>\n",
       "      <td>0.959254</td>\n",
       "      <td>0.975142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.689231</td>\n",
       "      <td>0.576976</td>\n",
       "      <td>0.890825</td>\n",
       "      <td>0.957491</td>\n",
       "      <td>0.977725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.683736</td>\n",
       "      <td>0.590818</td>\n",
       "      <td>0.890663</td>\n",
       "      <td>0.958739</td>\n",
       "      <td>0.975497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.685921</td>\n",
       "      <td>0.588587</td>\n",
       "      <td>0.890566</td>\n",
       "      <td>0.957351</td>\n",
       "      <td>0.975784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  F1 (macro)  F1 (micro)      LRAP      NDCG\n",
       "0  0.687689    0.599925    0.891609  0.958868  0.975660\n",
       "1  0.683886    0.590739    0.891490  0.959254  0.975142\n",
       "2  0.689231    0.576976    0.890825  0.957491  0.977725\n",
       "3  0.683736    0.590818    0.890663  0.958739  0.975497\n",
       "4  0.685921    0.588587    0.890566  0.957351  0.975784"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy      0.686092\n",
      "F1 (macro)    0.589409\n",
      "F1 (micro)    0.891031\n",
      "LRAP          0.958341\n",
      "NDCG          0.975961\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.cnn_bi_lstm_1, model_params={\n",
    "    \"filters_1\": 400, \"filters_2\": 500, \"loss\": \"binary_crossentropy\",\n",
    "    \"embedding_matrix\": w2v_embedding_matrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (None, 768, 300)          198020100 \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 767, 400)          240400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 767, 400)          1600      \n",
      "_________________________________________________________________\n",
      "re_lu_42 (ReLU)              (None, 767, 400)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 383, 400)          0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 383, 400)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 382, 500)          400500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 382, 500)          2000      \n",
      "_________________________________________________________________\n",
      "re_lu_43 (ReLU)              (None, 382, 500)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 191, 500)          0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 191, 500)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_19 (Bidirectio (None, 512)               1550336   \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 126)               64638     \n",
      "=================================================================\n",
      "Total params: 200,279,574\n",
      "Trainable params: 2,257,674\n",
      "Non-trainable params: 198,021,900\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 70s 75ms/step - loss: 0.0113 - val_loss: 0.0064\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 67s 72ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 67s 72ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0033Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 69s 73ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 00019: early stopping\n",
      "235/235 [==============================] - 5s 22ms/step\n",
      "{'accuracy': 0.6916084266008373, 'F1 (macro)': 0.5799627240704491, 'F1 (micro)': 0.8921506739588251, 'LRAP': 0.956311472927769, 'NDCG': 0.9743929078723703}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 71s 75ms/step - loss: 0.0111 - val_loss: 0.0064\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 65s 70ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0034Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 68s 73ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 00017: early stopping\n",
      "235/235 [==============================] - 5s 22ms/step\n",
      "{'accuracy': 0.6892065451270162, 'F1 (macro)': 0.5719609106944802, 'F1 (micro)': 0.890860530954543, 'LRAP': 0.9557170618977122, 'NDCG': 0.973186432714401}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 71s 75ms/step - loss: 0.0111 - val_loss: 0.0062\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 66s 71ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0032Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 00020: early stopping\n",
      "235/235 [==============================] - 5s 22ms/step\n",
      "{'accuracy': 0.6948016210536849, 'F1 (macro)': 0.5827138380652194, 'F1 (micro)': 0.8931531210150386, 'LRAP': 0.9558124373620458, 'NDCG': 0.9767469254140364}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 70s 75ms/step - loss: 0.0114 - val_loss: 0.0066\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 66s 71ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 65s 70ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 65s 70ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 65s 70ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 66s 71ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 65s 70ms/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 66s 71ms/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 25/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 26/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0030Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 69s 73ms/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 00026: early stopping\n",
      "235/235 [==============================] - 5s 22ms/step\n",
      "{'accuracy': 0.6932597201140893, 'F1 (macro)': 0.5928809852157991, 'F1 (micro)': 0.8925406576369458, 'LRAP': 0.9567144119227947, 'NDCG': 0.974220369958567}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 71s 75ms/step - loss: 0.0111 - val_loss: 0.0063\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 67s 71ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 66s 70ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0032Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 69s 73ms/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 00023: early stopping\n",
      "235/235 [==============================] - 5s 22ms/step\n",
      "{'accuracy': 0.6987473520924724, 'F1 (macro)': 0.5924234590213148, 'F1 (micro)': 0.8932903212114137, 'LRAP': 0.9558369108871984, 'NDCG': 0.9747912309731211}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1 (macro)</th>\n",
       "      <th>F1 (micro)</th>\n",
       "      <th>LRAP</th>\n",
       "      <th>NDCG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.691608</td>\n",
       "      <td>0.579963</td>\n",
       "      <td>0.892151</td>\n",
       "      <td>0.956311</td>\n",
       "      <td>0.974393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.689207</td>\n",
       "      <td>0.571961</td>\n",
       "      <td>0.890861</td>\n",
       "      <td>0.955717</td>\n",
       "      <td>0.973186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.694802</td>\n",
       "      <td>0.582714</td>\n",
       "      <td>0.893153</td>\n",
       "      <td>0.955812</td>\n",
       "      <td>0.976747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.693260</td>\n",
       "      <td>0.592881</td>\n",
       "      <td>0.892541</td>\n",
       "      <td>0.956714</td>\n",
       "      <td>0.974220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.698747</td>\n",
       "      <td>0.592423</td>\n",
       "      <td>0.893290</td>\n",
       "      <td>0.955837</td>\n",
       "      <td>0.974791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  F1 (macro)  F1 (micro)      LRAP      NDCG\n",
       "0  0.691608    0.579963    0.892151  0.956311  0.974393\n",
       "1  0.689207    0.571961    0.890861  0.955717  0.973186\n",
       "2  0.694802    0.582714    0.893153  0.955812  0.976747\n",
       "3  0.693260    0.592881    0.892541  0.956714  0.974220\n",
       "4  0.698747    0.592423    0.893290  0.955837  0.974791"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy      0.693525\n",
      "F1 (macro)    0.583988\n",
      "F1 (micro)    0.892399\n",
      "LRAP          0.956078\n",
      "NDCG          0.974668\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.cnn_bi_lstm_1, model_params={\n",
    "    \"filters_1\": 400, \"filters_2\": 500, \"loss\": \"mean_squared_error\",\n",
    "    \"embedding_matrix\": w2v_embedding_matrix})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
