{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import pickle\n",
    "import random as rn\n",
    "import warnings\n",
    "from importlib import reload\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from gensim.models import Word2Vec\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import accuracy_score, f1_score, hamming_loss, \\\n",
    "        average_precision_score, ndcg_score, \\\n",
    "        label_ranking_average_precision_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.distribute import MirroredStrategy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import Constant, GlorotUniform\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Embedding, Conv1D, \\\n",
    "        GlobalMaxPooling1D, SpatialDropout1D, LSTM, GRU, Flatten, MaxPooling1D, \\\n",
    "        BatchNormalization, ReLU, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import data\n",
    "import models\n",
    "import preprocessing\n",
    "\n",
    "seed = 0\n",
    "sns.set()\n",
    "\n",
    "def reset_seed():\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "    np.random.seed(seed)\n",
    "    rn.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Extracting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299773,)\n",
      "(299773, 126)\n",
      "Toronto stocks end higher after volatile session. CHANGE\t\t\t\t    CHANGE TSE\t  5900.37    +50.15   HI 5900.37\t    LO  5840.29 DJI\t  6611.05    +27.57   GOLD (LONDON)   US$350.00 +1.90 FTSE100    4248.10    -64.80   GOLD (NY-COMEX) US$354.80 +0.70 NIKKEI    17869.59   -133.81   LME CASH NICKEL US$7659   +99.0 CANDLR\t1.3883\t\t LME CASH ALUM   US$1602.0  -4.0 CAN 30-YR   107.41     -0.15   BRENT CRUDE     US$19.09  -0.27 --------------------MARKET COMMENT---------------------------- * Toronto stocks ended higher on Tuesday, buoyed by strength in golds and banking * Computer problems due to heavy trading in Bre-X Minerals hampered session * 84 million shares traded Toronto's key stock index ended higher on Tuesday as the saga of Bre-X Minerals Ltd and its Indonesian gold find continued to dominate Canada's biggest stock market. The TSE 300 Index climbed 50.15 points to close at 5900.37 in heavy turnover of 84.07 million shares worth C$1.4 billion. But the overall market was mixed with declining issues narrowly outpacing advances 476 to 464. 298 issues were flat. Frantic trading in Bre-X collapsed the TSE's computer trading system earlier in the day, forcing the exchange to halt trading in the stock before the market closed. Shares in the Calgary-based gold prospector were halted for a statement by the company this morning. When it resumed, a whopping 7.7 million shares changed hands in the first 22 minutes of trading before the system crashed. Bre-X closed up 1.35 at 3.85. It was the first time Bre-X traded since investors lopped nearly C$3 billion off its stock market value last Thursday. TSE officials said the trading problems were due to old technology which will be replaced. On the Montreal Exchange, Bre-X closed up 0.81 at 3.50 on 9.8 million shares. Analysts predicted more volatility for Bre-X shares this week. \"The question of what Bre-X will release over the next few days will be important to the market,\" said Josef Schachter, of Schachter Asset Management Inc. The gold sector rose nearly 136 points, leading 12 of 14 sub-indices higher. Other strong groups included financial services, consumer products, energy and transportation. The TSE posted minor losses in forestry and real estate. --- HOT STOCKS --- * Among bank shares, Bank of Nova Scotia rose 0.65 to 51.50 on 2.1 million shares, while Canadian Imperial Bank of Commerce added 0.50 to 31.80 on 2.1 million shares. ((Reuters Toronto Bureau (416) 941-8100))\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# data.extract_data(extraction_dir=\"train\",\n",
    "#                   data_dir=\"data\",\n",
    "#                   data_zip_name=\"reuters-training-corpus.zip\")\n",
    "\n",
    "train_df = pd.read_pickle(\"train/data.pkl\")\n",
    "\n",
    "# train_df = data.get_docs_labels(\"train/REUTERS_CORPUS_2\")\n",
    "# train_df.to_pickle(\"train/data.pkl\")\n",
    "\n",
    "train_docs = train_df[\"doc\"].values\n",
    "train_labels = np.array(train_df[\"labels\"].tolist())\n",
    "n_labels = len(data.CODEMAP)\n",
    "\n",
    "print(train_docs.shape)\n",
    "print(train_labels.shape)\n",
    "print(train_docs[2])\n",
    "print(train_labels[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocessing the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toronto stocks end higher after volatile session . CHANGE CHANGE TSE 5900.37 +50.15 HI 5900.37 LO 5840.29 DJI 6611.05 +27.57 GOLD ( LONDON ) US$ 350.00 +1.90 FTSE100 4248.10 -64.80 GOLD ( NY - COMEX ) US$ 354.80 +0.70 NIKKEI 17869.59 -133.81 LME CASH NICKEL US$ 7659 +99.0 CANDLR 1.3883 LME CASH ALUM US$ 1602.0 -4.0 CAN 30-YR 107.41 -0.15 BRENT CRUDE US$ 19.09 -0.27 --------------------MARKET COMMENT---------------------------- * Toronto stocks ended higher on Tuesday , buoyed by strength in golds and banking * Computer problems due to heavy trading in Bre - X Minerals hampered session * 84 million shares traded Toronto 's key stock index ended higher on Tuesday as the saga of Bre - X Minerals Ltd and its Indonesian gold find continued to dominate Canada 's biggest stock market . The TSE 300 Index climbed 50.15 points to close at 5900.37 in heavy turnover of 84.07 million shares worth C$ 1.4 billion . But the overall market was mixed with declining issues narrowly outpacing advances 476 to 464 . 298 issues were flat . Frantic trading in Bre - X collapsed the TSE 's computer trading system earlier in the day , forcing the exchange to halt trading in the stock before the market closed . Shares in the Calgary - based gold prospector were halted for a statement by the company this morning . When it resumed , a whopping 7.7 million shares changed hands in the first 22 minutes of trading before the system crashed . Bre - X closed up 1.35 at 3.85 . It was the first time Bre - X traded since investors lopped nearly C$ 3 billion off its stock market value last Thursday . TSE officials said the trading problems were due to old technology which will be replaced . On the Montreal Exchange , Bre - X closed up 0.81 at 3.50 on 9.8 million shares . Analysts predicted more volatility for Bre - X shares this week . \" The question of what Bre - X will release over the next few days will be important to the market , \" said Josef Schachter , of Schachter Asset Management Inc. The gold sector rose nearly 136 points , leading 12 of 14 sub - indices higher . Other strong groups included financial services , consumer products , energy and transportation . The TSE posted minor losses in forestry and real estate . --- HOT STOCKS --- * Among bank shares , Bank of Nova Scotia rose 0.65 to 51.50 on 2.1 million shares , while Canadian Imperial Bank of Commerce added 0.50 to 31.80 on 2.1 million shares . ( ( Reuters Toronto Bureau ( 416 ) 941 - 8100 ) )\n"
     ]
    }
   ],
   "source": [
    "path_to_preprocessed_train_docs = \"train/preprocessed_docs.pkl\" # tokenization only\n",
    "# path_to_preprocessed_train_docs = \"train/preprocessed_docs_lemmatized_no_sw.pkl\"\n",
    "\n",
    "with open(path_to_preprocessed_train_docs, \"rb\") as f:\n",
    "    preprocessed_train_docs = pickle.load(f)\n",
    "\n",
    "# preprocessed_train_docs = preprocessing.preprocess_corpus(train_docs)\n",
    "# with open(path_to_preprocessed_train_docs, \"wb\") as f:\n",
    "#     pickle.dump(preprocessed_train_docs, f)\n",
    "\n",
    "print(preprocessed_train_docs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing the documents as token index sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = preprocessed_train_docs\n",
    "n_vocabulary = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=n_vocabulary, filters=\"\", lower=False)\n",
    "tokenizer.fit_on_texts(docs)\n",
    "word_idx = tokenizer.word_index\n",
    "if n_vocabulary is None:\n",
    "    n_vocabulary = len(word_idx)\n",
    "\n",
    "print(n_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "(299773, 256)\n",
      "[ 2112   217   137   145    52  2639   593     2  3714  3714  9473  8514\n",
      "  9051  4802    14  2981    13   587  4802    14  3274     7  3355    13\n",
      "   587 15304  1660  5594 16940   587  1660  5594   587 14783  1709 11671\n",
      " 15729 13077   587    38  2112   217   226   145    12    85     3  5774\n",
      "    23  1043     6 11672     9   809    38  3318   700   167     4   901\n",
      "   181     6  3495     7  1927  6603  9271   593    38  4214    31    75\n",
      "   418  2112    15   435   150   180   226   145    12    85    30     1\n",
      " 15801     5  3495     7  1927  6603   200     9    32  1780   441  1151\n",
      "   598     4  7599   622]\n"
     ]
    }
   ],
   "source": [
    "n_sequence = 256\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(docs)\n",
    "if n_sequence is None:\n",
    "    n_sequence = max([len(s) for s in sequences])\n",
    "sequence_lengths = [min(len(s), n_sequence) for s in sequences]\n",
    "sequences = pad_sequences(sequences,\n",
    "                          maxlen=n_sequence,\n",
    "                          padding=\"post\",\n",
    "                          truncating=\"post\")\n",
    "\n",
    "print(n_sequence)\n",
    "print(sequences.shape)\n",
    "print(sequences[2][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_lengths = [len(doc.split()) for doc in docs]\n",
    "\n",
    "sns.distplot(doc_lengths,\n",
    "             bins=np.arange(0, 2500, 25),\n",
    "             kde=False,\n",
    "             label=\"documents\")\n",
    "sns.distplot(sequence_lengths,\n",
    "             bins=np.arange(0, 2500, 25),\n",
    "             kde=False,\n",
    "             label=\"sequences\")\n",
    "total_word_coverage = np.round(np.sum(sequence_lengths) / np.sum(doc_lengths), 3)\n",
    "plt.title(f\"n_vocabulary={n_vocabulary}, n_sequence={n_sequence},\\n\"\n",
    "          f\"total_word_coverage={total_word_coverage}\")\n",
    "plt.xlim(0, 1550)\n",
    "plt.xlabel(\"length\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_embedding = 300 # 300 required by FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191252\n",
      "['the', '.', ',', 'to', 'of', 'in', '-', 'a', 'and', '\"', 'said', 'on', ')', '(', \"'s\", 'for', 'The', 'at', 'was', '$', 'that', 'is', 'by', 'with', 'from', 'percent', 'it', 'be', '/', 'as', 'million', 'its', 'will', 'has', '--', 'were', 'not', '*', 'would', 'year', 'are', 'have', 'an', 'he', 'which', ':', 'had', 'market', 'up', 'A', 'but', 'after', 'N', 'this', 'company', 'one', 'been', 'U.S.', 'billion', 'also', 'government', 'last', 'or', '1997', 'two', 'their', 'they', 'first', 'over', 'new', '1', 'his', 'more', 'June', 'shares', 'about', 'week', 'It', 'than', 'share', 'Bank', 'who', 'I', '1996', 'Tuesday', '%', 'per', 'Wednesday', 'May', 'we', 'expected', 'July', 'Thursday', 'Monday', 'We', 'some', 'Friday', 'down', 'could', 'three']\n"
     ]
    }
   ],
   "source": [
    "reset_seed()\n",
    "\n",
    "window = 5\n",
    "w2v_path = f\"data/w2v_{window}_{n_embedding}_train.model\"\n",
    "\n",
    "try:\n",
    "    w2v_embedding_model = Word2Vec.load(w2v_path)\n",
    "except:\n",
    "    w2v_embedding_model = Word2Vec(sentences=[s.split() for s in docs],\n",
    "                                   size=n_embedding, \n",
    "                                   window=window,\n",
    "                                   min_count=5,\n",
    "                                   sg=1,\n",
    "                                   workers=cpu_count(),\n",
    "                                   seed=seed)\n",
    "    w2v_embedding_model.save(w2v_path)\n",
    "\n",
    "print(len(list(w2v_embedding_model.wv.vocab)))\n",
    "print(w2v_embedding_model.wv.index2entity[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', 'the', '.', 'and', 'to', 'of', 'a', 'in', 'is', 'for', 'that', 'I', 'it', 'on', 'with', ')', ':', '\"', '(', 'The', 'you', 'was', 'are', 'or', 'this', 'as', 'have', 'at', 'from', '!', \"'s\", 'but', 'by', 'not', '?', 'your', 'all', '/', 'be', 'we', 'my', 'one', '-', 'will', 'they', 'so', 'which', '”', '“', 'has', '...', 'just', 'he', 'their', 'can', 'about', 'his', 'our', ';', 'when', 'more', 'had', 'do', 'some', 'time', 'like', 'also', 'there', 'them', 'get', 'what', 'out', \"'\", 'me', 'her', 'an', 'were', 'This', 'It', 'up', 'would', 'if', 'who', 'new', 'only', 'A', '–', 'people', 'any', 'We', 'make', 'other', 'In', 'then', 'its', 'use', 'said', 'now', 'no', 'first']\n"
     ]
    }
   ],
   "source": [
    "def load_vectors(fname): # from https://fasttext.cc/docs/en/english-vectors.html\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = np.array(list(map(float, tokens[1:])))\n",
    "    return data\n",
    "\n",
    "ft_embedding_model = load_vectors(\"data/crawl-300d-2M.vec\")\n",
    "\n",
    "token_iter = iter(ft_embedding_model)\n",
    "print([next(token_iter) for i in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_embedding_matrix(embedding_model):\n",
    "    embedding_matrix = np.zeros((n_vocabulary, n_embedding))\n",
    "    unknown_token_count = 0\n",
    "    for token, i in word_idx.items():\n",
    "        if i >= n_vocabulary:\n",
    "            continue\n",
    "        if token in embedding_model:\n",
    "            embedding_matrix[i] = embedding_model[token]\n",
    "        else:\n",
    "            embedding_matrix[i] = np.zeros(n_embedding)\n",
    "            unknown_token_count += 1\n",
    "\n",
    "    print(unknown_token_count)\n",
    "    print(embedding_matrix.shape)\n",
    "    print(embedding_matrix[1][:50])\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(20000, 300)\n",
      "[ 0.0552584   0.01123355  0.05852774  0.03515947  0.11631026 -0.02895849\n",
      "  0.17440622 -0.07505921  0.31014937  0.18220782 -0.153667    0.12877345\n",
      " -0.16599374 -0.03246057  0.14044979  0.0378183   0.01423781  0.20776965\n",
      "  0.25640684 -0.29507896  0.05467122 -0.19314985  0.16100715  0.16121837\n",
      "  0.10513832 -0.14126474 -0.10564382  0.07230753 -0.2635389   0.11694992\n",
      "  0.22365659  0.10568991 -0.20522533 -0.00804843 -0.11998951  0.02327573\n",
      "  0.23315957 -0.22042817 -0.04073263 -0.07091328 -0.26871315  0.40764555\n",
      " -0.12853378 -0.1205063  -0.04120149 -0.03833532  0.09974524 -0.1054061\n",
      " -0.04243345 -0.16846807]\n"
     ]
    }
   ],
   "source": [
    "w2v_embedding_matrix = create_embedding_matrix(w2v_embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687\n",
      "(20000, 300)\n",
      "[ 0.0231  0.017   0.0157 -0.0773  0.1088  0.0031 -0.1487 -0.2672 -0.0357\n",
      " -0.0487  0.0807  0.1532 -0.0739 -0.0291 -0.0445 -0.0014  0.1014  0.0186\n",
      " -0.0253  0.02   -0.0026 -0.0179  0.0005  0.0054 -0.0134  0.0233 -0.0755\n",
      " -0.0156  0.0415 -0.4985  0.041  -0.0616  0.0047  0.0325 -0.0162 -0.0172\n",
      "  0.0988  0.0766 -0.0796 -0.0345  0.0124 -0.1007 -0.0292 -0.0762 -0.1261\n",
      " -0.0531  0.0424  0.0144 -0.0683  0.2859]\n"
     ]
    }
   ],
   "source": [
    "ft_embedding_matrix = create_embedding_matrix(ft_embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = None\n",
    "x_train, y_train = shuffle(sequences,\n",
    "                           train_labels,\n",
    "                           random_state=seed,\n",
    "                           n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-evaluating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_evaluate(model_initializer, embedding_matrix, loss, batch_size=256):\n",
    "    kfold = KFold(n_splits=5)\n",
    "    cv_scores = []\n",
    "\n",
    "    model_initializer(embedding_matrix, n_vocabulary, n_embedding, n_sequence,\n",
    "                      n_labels, loss).summary()\n",
    "\n",
    "    for train, val in kfold.split(x_train, y_train):\n",
    "        model = model_initializer(embedding_matrix, n_vocabulary, n_embedding,\n",
    "                                  n_sequence, n_labels, loss)\n",
    "        es = EarlyStopping(patience=3, verbose=1, restore_best_weights=True)\n",
    "        history = model.fit(x_train[train],\n",
    "                            y_train[train],\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=100,\n",
    "                            verbose=1,\n",
    "                            validation_data=(x_train[val], y_train[val]),\n",
    "                            callbacks=[es])\n",
    "\n",
    "        y_pred_prob = model.predict(x_train[val], batch_size=batch_size, verbose=1)\n",
    "        y_pred = np.round(y_pred_prob)\n",
    "\n",
    "        scores = {}\n",
    "        scores[\"accuracy\"] = accuracy_score(y_train[val], y_pred)\n",
    "        scores[\"F1 (macro)\"] = f1_score(y_train[val], y_pred, average=\"macro\")\n",
    "        scores[\"F1 (micro)\"] = f1_score(y_train[val], y_pred, average=\"micro\")\n",
    "        scores[\"LRAP\"] = label_ranking_average_precision_score(y_train[val],\n",
    "                                                               y_pred_prob)\n",
    "        scores[\"NDCG\"] = ndcg_score(y_train[val], y_pred_prob)\n",
    "        cv_scores.append(scores)\n",
    "        print(scores)\n",
    "\n",
    "    cv_scores_df = pd.DataFrame(cv_scores)\n",
    "    display(cv_scores_df)\n",
    "    print(cv_scores_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from '/projappl/project_2002961/DL-2020-Shakespeare/models.py'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 256, 300)          6000000   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 255, 400)          240400    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 255, 400)          1600      \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 255, 400)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 127, 400)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 127, 400)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 126, 500)          400500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 126, 500)          2000      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 126, 500)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 63, 500)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 500)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 512)               1550336   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 126)               64638     \n",
      "=================================================================\n",
      "Total params: 8,259,474\n",
      "Trainable params: 2,257,674\n",
      "Non-trainable params: 6,001,800\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1\n",
      "937/937 [==============================] - 32s 34ms/step - loss: 0.0413 - val_loss: 0.0229\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0204 - val_loss: 0.0184\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0177 - val_loss: 0.0171\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0163 - val_loss: 0.0163\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0154 - val_loss: 0.0158\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0146 - val_loss: 0.0156\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0141 - val_loss: 0.0154\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0136 - val_loss: 0.0153\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0132 - val_loss: 0.0153\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0128 - val_loss: 0.0152\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0125 - val_loss: 0.0153\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0121 - val_loss: 0.0152\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0119 - val_loss: 0.0153\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0116 - val_loss: 0.0153\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0113Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0113 - val_loss: 0.0156\n",
      "Epoch 00015: early stopping\n",
      "235/235 [==============================] - 2s 9ms/step\n",
      "{'accuracy': 0.6913685263947961, 'F1 (macro)': 0.6039873137750196, 'F1 (micro)': 0.8924584175715122, 'LRAP': 0.9594435776372011, 'NDCG': 0.9764219296443024}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1\n",
      "937/937 [==============================] - 31s 33ms/step - loss: 0.0412 - val_loss: 0.0223\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0203 - val_loss: 0.0182\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0176 - val_loss: 0.0169\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0162 - val_loss: 0.0163\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0153 - val_loss: 0.0161\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0146 - val_loss: 0.0155\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0140 - val_loss: 0.0154\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0136 - val_loss: 0.0152\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0132 - val_loss: 0.0153\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0125Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0125 - val_loss: 0.0153\n",
      "Epoch 00011: early stopping\n",
      "235/235 [==============================] - 2s 9ms/step\n",
      "{'accuracy': 0.6827453923776166, 'F1 (macro)': 0.5934811676437554, 'F1 (micro)': 0.890020517768812, 'LRAP': 0.9578905635082711, 'NDCG': 0.9755271300582664}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1\n",
      "937/937 [==============================] - 31s 34ms/step - loss: 0.0396 - val_loss: 0.0222\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0199 - val_loss: 0.0183\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0161 - val_loss: 0.0163\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0153 - val_loss: 0.0161\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0146 - val_loss: 0.0159\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0141 - val_loss: 0.0155\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0136 - val_loss: 0.0156\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0132 - val_loss: 0.0153\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0128 - val_loss: 0.0155\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0125 - val_loss: 0.0155\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0122Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0122 - val_loss: 0.0154\n",
      "Epoch 00012: early stopping\n",
      "235/235 [==============================] - 2s 9ms/step\n",
      "{'accuracy': 0.6841631223417564, 'F1 (macro)': 0.5961645826055675, 'F1 (micro)': 0.890359747178997, 'LRAP': 0.9584550335607556, 'NDCG': 0.9761243025484498}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1\n",
      "937/937 [==============================] - 31s 33ms/step - loss: 0.0411 - val_loss: 0.0231\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0202 - val_loss: 0.0183\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0175 - val_loss: 0.0170\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0162 - val_loss: 0.0164\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0153 - val_loss: 0.0161\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0146 - val_loss: 0.0155\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0141 - val_loss: 0.0154\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0136 - val_loss: 0.0154\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0132 - val_loss: 0.0157\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0128 - val_loss: 0.0152\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0124 - val_loss: 0.0152\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0121 - val_loss: 0.0153\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0118Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0118 - val_loss: 0.0152\n",
      "Epoch 00013: early stopping\n",
      "235/235 [==============================] - 2s 9ms/step\n",
      "{'accuracy': 0.6887447042732762, 'F1 (macro)': 0.6018351074914913, 'F1 (micro)': 0.892833987823841, 'LRAP': 0.9588381070898767, 'NDCG': 0.9762718476796477}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1\n",
      "937/937 [==============================] - 31s 34ms/step - loss: 0.0402 - val_loss: 0.0221\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0201 - val_loss: 0.0189\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0175 - val_loss: 0.0170\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0162 - val_loss: 0.0163\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0153 - val_loss: 0.0160\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0146 - val_loss: 0.0157\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0141 - val_loss: 0.0154\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0136 - val_loss: 0.0154\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0132 - val_loss: 0.0155\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0124 - val_loss: 0.0153\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0118 - val_loss: 0.0154\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0116Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0116 - val_loss: 0.0155\n",
      "Epoch 00014: early stopping\n",
      "235/235 [==============================] - 2s 9ms/step\n",
      "{'accuracy': 0.6865763752210028, 'F1 (macro)': 0.6047928990414956, 'F1 (micro)': 0.8908684202176603, 'LRAP': 0.9583675457010429, 'NDCG': 0.9757653215648612}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1 (macro)</th>\n",
       "      <th>F1 (micro)</th>\n",
       "      <th>LRAP</th>\n",
       "      <th>NDCG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.691369</td>\n",
       "      <td>0.603987</td>\n",
       "      <td>0.892458</td>\n",
       "      <td>0.959444</td>\n",
       "      <td>0.976422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.682745</td>\n",
       "      <td>0.593481</td>\n",
       "      <td>0.890021</td>\n",
       "      <td>0.957891</td>\n",
       "      <td>0.975527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.684163</td>\n",
       "      <td>0.596165</td>\n",
       "      <td>0.890360</td>\n",
       "      <td>0.958455</td>\n",
       "      <td>0.976124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.688745</td>\n",
       "      <td>0.601835</td>\n",
       "      <td>0.892834</td>\n",
       "      <td>0.958838</td>\n",
       "      <td>0.976272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.686576</td>\n",
       "      <td>0.604793</td>\n",
       "      <td>0.890868</td>\n",
       "      <td>0.958368</td>\n",
       "      <td>0.975765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  F1 (macro)  F1 (micro)      LRAP      NDCG\n",
       "0  0.691369    0.603987    0.892458  0.959444  0.976422\n",
       "1  0.682745    0.593481    0.890021  0.957891  0.975527\n",
       "2  0.684163    0.596165    0.890360  0.958455  0.976124\n",
       "3  0.688745    0.601835    0.892834  0.958838  0.976272\n",
       "4  0.686576    0.604793    0.890868  0.958368  0.975765"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy      0.686720\n",
      "F1 (macro)    0.600052\n",
      "F1 (micro)    0.891308\n",
      "LRAP          0.958599\n",
      "NDCG          0.976022\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.init_cnn_bi_lstm_1, ft_embedding_matrix, \"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 256, 300)          6000000   \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 255, 400)          240400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 255, 400)          1600      \n",
      "_________________________________________________________________\n",
      "re_lu_12 (ReLU)              (None, 255, 400)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 127, 400)          0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 127, 400)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 126, 500)          400500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 126, 500)          2000      \n",
      "_________________________________________________________________\n",
      "re_lu_13 (ReLU)              (None, 126, 500)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 63, 500)           0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 63, 500)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 512)               1550336   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 126)               64638     \n",
      "=================================================================\n",
      "Total params: 8,259,474\n",
      "Trainable params: 2,257,674\n",
      "Non-trainable params: 6,001,800\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 31s 33ms/step - loss: 0.0110 - val_loss: 0.0066\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 27s 29ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0031Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 00017: early stopping\n",
      "235/235 [==============================] - 2s 9ms/step\n",
      "{'accuracy': 0.695421566174631, 'F1 (macro)': 0.5939234599015467, 'F1 (micro)': 0.8924249084249084, 'LRAP': 0.9571299521374025, 'NDCG': 0.975069208616045}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 31s 33ms/step - loss: 0.0109 - val_loss: 0.0063\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0031Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 00018: early stopping\n",
      "235/235 [==============================] - 2s 9ms/step\n",
      "{'accuracy': 0.6990075890251022, 'F1 (macro)': 0.5954689636005959, 'F1 (micro)': 0.8939446137538095, 'LRAP': 0.9573017925274987, 'NDCG': 0.9750089289372285}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 31s 33ms/step - loss: 0.0106 - val_loss: 0.0064\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0033Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 00014: early stopping\n",
      "235/235 [==============================] - 2s 9ms/step\n",
      "{'accuracy': 0.692552747894254, 'F1 (macro)': 0.5840406931765899, 'F1 (micro)': 0.8913256522314925, 'LRAP': 0.9560808931302488, 'NDCG': 0.9745814503258573}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 31s 33ms/step - loss: 0.0108 - val_loss: 0.0064\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0032Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 00017: early stopping\n",
      "235/235 [==============================] - 2s 9ms/step\n",
      "{'accuracy': 0.6964672915902191, 'F1 (macro)': 0.5959119792566243, 'F1 (micro)': 0.8934850546366766, 'LRAP': 0.9570265160619413, 'NDCG': 0.9751618510374368}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 31s 34ms/step - loss: 0.0108 - val_loss: 0.0061\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0033Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 00014: early stopping\n",
      "235/235 [==============================] - 2s 9ms/step\n",
      "{'accuracy': 0.6917636854922107, 'F1 (macro)': 0.5775558807536102, 'F1 (micro)': 0.8923245887461965, 'LRAP': 0.9565074870950019, 'NDCG': 0.9746893830347487}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1 (macro)</th>\n",
       "      <th>F1 (micro)</th>\n",
       "      <th>LRAP</th>\n",
       "      <th>NDCG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.695422</td>\n",
       "      <td>0.593923</td>\n",
       "      <td>0.892425</td>\n",
       "      <td>0.957130</td>\n",
       "      <td>0.975069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.699008</td>\n",
       "      <td>0.595469</td>\n",
       "      <td>0.893945</td>\n",
       "      <td>0.957302</td>\n",
       "      <td>0.975009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.692553</td>\n",
       "      <td>0.584041</td>\n",
       "      <td>0.891326</td>\n",
       "      <td>0.956081</td>\n",
       "      <td>0.974581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.696467</td>\n",
       "      <td>0.595912</td>\n",
       "      <td>0.893485</td>\n",
       "      <td>0.957027</td>\n",
       "      <td>0.975162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.691764</td>\n",
       "      <td>0.577556</td>\n",
       "      <td>0.892325</td>\n",
       "      <td>0.956507</td>\n",
       "      <td>0.974689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  F1 (macro)  F1 (micro)      LRAP      NDCG\n",
       "0  0.695422    0.593923    0.892425  0.957130  0.975069\n",
       "1  0.699008    0.595469    0.893945  0.957302  0.975009\n",
       "2  0.692553    0.584041    0.891326  0.956081  0.974581\n",
       "3  0.696467    0.595912    0.893485  0.957027  0.975162\n",
       "4  0.691764    0.577556    0.892325  0.956507  0.974689"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy      0.695043\n",
      "F1 (macro)    0.589380\n",
      "F1 (micro)    0.892701\n",
      "LRAP          0.956809\n",
      "NDCG          0.974902\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.init_cnn_bi_lstm_1, ft_embedding_matrix, \"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_24 (Embedding)     (None, 256, 300)          6000000   \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 255, 400)          240400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 255, 400)          1600      \n",
      "_________________________________________________________________\n",
      "re_lu_44 (ReLU)              (None, 255, 400)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 127, 400)          0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 127, 400)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 126, 500)          400500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 126, 500)          2000      \n",
      "_________________________________________________________________\n",
      "re_lu_45 (ReLU)              (None, 126, 500)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 63, 500)           0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 63, 500)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_12 (Bidirectio (None, 512)               1550336   \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 126)               32382     \n",
      "=================================================================\n",
      "Total params: 8,358,546\n",
      "Trainable params: 2,356,746\n",
      "Non-trainable params: 6,001,800\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 31s 34ms/step - loss: 0.0485 - val_loss: 0.0233\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0236 - val_loss: 0.0191\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0202 - val_loss: 0.0174\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0186 - val_loss: 0.0171\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0176 - val_loss: 0.0164\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0169 - val_loss: 0.0161\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0162 - val_loss: 0.0161\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0158 - val_loss: 0.0158\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0153 - val_loss: 0.0161\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0149 - val_loss: 0.0157\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0146 - val_loss: 0.0158\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0142 - val_loss: 0.0158\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0140Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0140 - val_loss: 0.0158\n",
      "Epoch 00013: early stopping\n",
      "235/235 [==============================] - 2s 9ms/step\n",
      "{'accuracy': 0.6886331415228087, 'F1 (macro)': 0.5616883097875265, 'F1 (micro)': 0.8901064002967571, 'LRAP': 0.9576013483384154, 'NDCG': 0.9754267960477201}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 31s 34ms/step - loss: 0.0483 - val_loss: 0.0229\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0236 - val_loss: 0.0188\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0204 - val_loss: 0.0173\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0188 - val_loss: 0.0175\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0177 - val_loss: 0.0164\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0170 - val_loss: 0.0162\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0163 - val_loss: 0.0159\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0159 - val_loss: 0.0159\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0154 - val_loss: 0.0157\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0150 - val_loss: 0.0158\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0147 - val_loss: 0.0158\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0144 - val_loss: 0.0156\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0140 - val_loss: 0.0160\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0138 - val_loss: 0.0161\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0135Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0135 - val_loss: 0.0161\n",
      "Epoch 00015: early stopping\n",
      "235/235 [==============================] - 2s 9ms/step\n",
      "{'accuracy': 0.6919189392044033, 'F1 (macro)': 0.5718008519416119, 'F1 (micro)': 0.8917172060785491, 'LRAP': 0.9580079063140466, 'NDCG': 0.9755585691875649}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 32s 34ms/step - loss: 0.0491 - val_loss: 0.0239\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0239 - val_loss: 0.0193\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0205 - val_loss: 0.0179\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 29s 31ms/step - loss: 0.0188 - val_loss: 0.0171\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0178 - val_loss: 0.0168\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0170 - val_loss: 0.0164\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0164 - val_loss: 0.0163\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0159 - val_loss: 0.0163\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0155 - val_loss: 0.0158\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0150 - val_loss: 0.0160\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0147 - val_loss: 0.0160\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0144Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0144 - val_loss: 0.0160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00012: early stopping\n",
      "235/235 [==============================] - 2s 9ms/step\n",
      "{'accuracy': 0.6842298390459511, 'F1 (macro)': 0.5473916988829527, 'F1 (micro)': 0.8884200232779376, 'LRAP': 0.9558886627707551, 'NDCG': 0.974769574086155}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 34s 36ms/step - loss: 0.0485 - val_loss: 0.0236\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0238 - val_loss: 0.0195\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0206 - val_loss: 0.0178\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0190 - val_loss: 0.0173\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0179 - val_loss: 0.0166\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0170 - val_loss: 0.0163\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0164 - val_loss: 0.0160\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0159 - val_loss: 0.0158\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 29s 31ms/step - loss: 0.0154 - val_loss: 0.0161\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0150 - val_loss: 0.0158\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0147Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0147 - val_loss: 0.0158\n",
      "Epoch 00011: early stopping\n",
      "235/235 [==============================] - 2s 9ms/step\n",
      "{'accuracy': 0.6841578543550055, 'F1 (macro)': 0.5450232632009988, 'F1 (micro)': 0.8889155125317487, 'LRAP': 0.9552990597079933, 'NDCG': 0.9743234304903552}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 34s 36ms/step - loss: 0.0479 - val_loss: 0.0227\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0235 - val_loss: 0.0197\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0204 - val_loss: 0.0176\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0188 - val_loss: 0.0168\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0177 - val_loss: 0.0165\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0170 - val_loss: 0.0164\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0163 - val_loss: 0.0158\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0158 - val_loss: 0.0159\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0153 - val_loss: 0.0163\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0150 - val_loss: 0.0156\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0147 - val_loss: 0.0160\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.0143 - val_loss: 0.0158\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0140Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 32s 35ms/step - loss: 0.0140 - val_loss: 0.0160\n",
      "Epoch 00013: early stopping\n",
      "235/235 [==============================] - 2s 9ms/step\n",
      "{'accuracy': 0.6891116522667379, 'F1 (macro)': 0.5570157835966247, 'F1 (micro)': 0.8898548553636104, 'LRAP': 0.9571314574377705, 'NDCG': 0.9751197554467634}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1 (macro)</th>\n",
       "      <th>F1 (micro)</th>\n",
       "      <th>LRAP</th>\n",
       "      <th>NDCG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.688633</td>\n",
       "      <td>0.561688</td>\n",
       "      <td>0.890106</td>\n",
       "      <td>0.957601</td>\n",
       "      <td>0.975427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.691919</td>\n",
       "      <td>0.571801</td>\n",
       "      <td>0.891717</td>\n",
       "      <td>0.958008</td>\n",
       "      <td>0.975559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.684230</td>\n",
       "      <td>0.547392</td>\n",
       "      <td>0.888420</td>\n",
       "      <td>0.955889</td>\n",
       "      <td>0.974770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.684158</td>\n",
       "      <td>0.545023</td>\n",
       "      <td>0.888916</td>\n",
       "      <td>0.955299</td>\n",
       "      <td>0.974323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.689112</td>\n",
       "      <td>0.557016</td>\n",
       "      <td>0.889855</td>\n",
       "      <td>0.957131</td>\n",
       "      <td>0.975120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  F1 (macro)  F1 (micro)      LRAP      NDCG\n",
       "0  0.688633    0.561688    0.890106  0.957601  0.975427\n",
       "1  0.691919    0.571801    0.891717  0.958008  0.975559\n",
       "2  0.684230    0.547392    0.888420  0.955889  0.974770\n",
       "3  0.684158    0.545023    0.888916  0.955299  0.974323\n",
       "4  0.689112    0.557016    0.889855  0.957131  0.975120"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy      0.687610\n",
      "F1 (macro)    0.556584\n",
      "F1 (micro)    0.889803\n",
      "LRAP          0.956786\n",
      "NDCG          0.975040\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.init_cnn_bi_lstm_9, ft_embedding_matrix, \"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_34 (Embedding)     (None, 256, 300)          6000000   \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 255, 400)          240400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 255, 400)          1600      \n",
      "_________________________________________________________________\n",
      "re_lu_64 (ReLU)              (None, 255, 400)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_72 (MaxPooling (None, 127, 400)          0         \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 127, 400)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 126, 500)          400500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 126, 500)          2000      \n",
      "_________________________________________________________________\n",
      "re_lu_65 (ReLU)              (None, 126, 500)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_73 (MaxPooling (None, 63, 500)           0         \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 63, 500)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_22 (Bidirectio (None, 512)               1164288   \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 126)               64638     \n",
      "=================================================================\n",
      "Total params: 7,873,426\n",
      "Trainable params: 1,871,626\n",
      "Non-trainable params: 6,001,800\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 73s 78ms/step - loss: 0.0356 - val_loss: 0.0206\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 73s 77ms/step - loss: 0.0190 - val_loss: 0.0177\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0170 - val_loss: 0.0164\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0159 - val_loss: 0.0163\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 73s 77ms/step - loss: 0.0151 - val_loss: 0.0158\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0145 - val_loss: 0.0155\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0141 - val_loss: 0.0155\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0137 - val_loss: 0.0153\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0133 - val_loss: 0.0153\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0129 - val_loss: 0.0156\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0127 - val_loss: 0.0153\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0124 - val_loss: 0.0154\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0119Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0119 - val_loss: 0.0156\n",
      "Epoch 00014: early stopping\n",
      "235/235 [==============================] - 6s 24ms/step\n",
      "{'accuracy': 0.6884997081144192, 'F1 (macro)': 0.6012174163958385, 'F1 (micro)': 0.8913652724833641, 'LRAP': 0.9592302534407271, 'NDCG': 0.9763314455974065}\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 73s 78ms/step - loss: 0.0346 - val_loss: 0.0198\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0187 - val_loss: 0.0174\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0168 - val_loss: 0.0164\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0158 - val_loss: 0.0162\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0151 - val_loss: 0.0160\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0145 - val_loss: 0.0154\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0140 - val_loss: 0.0154\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0136 - val_loss: 0.0152\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0132 - val_loss: 0.0152\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0129 - val_loss: 0.0153\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 73s 78ms/step - loss: 0.0126 - val_loss: 0.0151\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0123 - val_loss: 0.0155\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0121 - val_loss: 0.0152\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0118Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0118 - val_loss: 0.0155\n",
      "Epoch 00014: early stopping\n",
      "235/235 [==============================] - 6s 24ms/step\n",
      "{'accuracy': 0.6893169877408056, 'F1 (macro)': 0.5972198552885364, 'F1 (micro)': 0.8923670224774308, 'LRAP': 0.9594450055384031, 'NDCG': 0.9762279800346599}\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 73s 78ms/step - loss: 0.0346 - val_loss: 0.0210\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 73s 77ms/step - loss: 0.0187 - val_loss: 0.0177\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 73s 77ms/step - loss: 0.0168 - val_loss: 0.0168\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0157 - val_loss: 0.0162\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0150 - val_loss: 0.0162\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0144 - val_loss: 0.0158\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0139 - val_loss: 0.0158\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0135 - val_loss: 0.0153\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0131 - val_loss: 0.0153\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0128 - val_loss: 0.0157\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0125Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0125 - val_loss: 0.0155\n",
      "Epoch 00011: early stopping\n",
      "235/235 [==============================] - 6s 24ms/step\n",
      "{'accuracy': 0.6838295388207822, 'F1 (macro)': 0.5946967521005567, 'F1 (micro)': 0.889572240629201, 'LRAP': 0.9585552712715919, 'NDCG': 0.9761813853689179}\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 73s 78ms/step - loss: 0.0349 - val_loss: 0.0206\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0189 - val_loss: 0.0179\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0168 - val_loss: 0.0167\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0158 - val_loss: 0.0162\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0150 - val_loss: 0.0158\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 73s 78ms/step - loss: 0.0145 - val_loss: 0.0156\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0140 - val_loss: 0.0154\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0136 - val_loss: 0.0152\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0132 - val_loss: 0.0152\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0129 - val_loss: 0.0153\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0125Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0125 - val_loss: 0.0153\n",
      "Epoch 00011: early stopping\n",
      "235/235 [==============================] - 6s 24ms/step\n",
      "{'accuracy': 0.6846081996197084, 'F1 (macro)': 0.6019218705595674, 'F1 (micro)': 0.8919014325681379, 'LRAP': 0.9582990918499233, 'NDCG': 0.9760143694889738}\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 73s 78ms/step - loss: 0.0357 - val_loss: 0.0205\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0189 - val_loss: 0.0176\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0168 - val_loss: 0.0168\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0158 - val_loss: 0.0163\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0150 - val_loss: 0.0159\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0145 - val_loss: 0.0158\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0140 - val_loss: 0.0153\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 78s 83ms/step - loss: 0.0136 - val_loss: 0.0154\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0132 - val_loss: 0.0154\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0129Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 72s 77ms/step - loss: 0.0129 - val_loss: 0.0155\n",
      "Epoch 00010: early stopping\n",
      "235/235 [==============================] - 6s 24ms/step\n",
      "{'accuracy': 0.6799879907929413, 'F1 (macro)': 0.5916816366634802, 'F1 (micro)': 0.8889774490424875, 'LRAP': 0.9574622048214575, 'NDCG': 0.9752469153903776}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1 (macro)</th>\n",
       "      <th>F1 (micro)</th>\n",
       "      <th>LRAP</th>\n",
       "      <th>NDCG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.688500</td>\n",
       "      <td>0.601217</td>\n",
       "      <td>0.891365</td>\n",
       "      <td>0.959230</td>\n",
       "      <td>0.976331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.689317</td>\n",
       "      <td>0.597220</td>\n",
       "      <td>0.892367</td>\n",
       "      <td>0.959445</td>\n",
       "      <td>0.976228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.683830</td>\n",
       "      <td>0.594697</td>\n",
       "      <td>0.889572</td>\n",
       "      <td>0.958555</td>\n",
       "      <td>0.976181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.684608</td>\n",
       "      <td>0.601922</td>\n",
       "      <td>0.891901</td>\n",
       "      <td>0.958299</td>\n",
       "      <td>0.976014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.679988</td>\n",
       "      <td>0.591682</td>\n",
       "      <td>0.888977</td>\n",
       "      <td>0.957462</td>\n",
       "      <td>0.975247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  F1 (macro)  F1 (micro)      LRAP      NDCG\n",
       "0  0.688500    0.601217    0.891365  0.959230  0.976331\n",
       "1  0.689317    0.597220    0.892367  0.959445  0.976228\n",
       "2  0.683830    0.594697    0.889572  0.958555  0.976181\n",
       "3  0.684608    0.601922    0.891901  0.958299  0.976014\n",
       "4  0.679988    0.591682    0.888977  0.957462  0.975247"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy      0.685248\n",
      "F1 (macro)    0.597348\n",
      "F1 (micro)    0.890837\n",
      "LRAP          0.958598\n",
      "NDCG          0.976000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.init_cnn_bi_gru_1, ft_embedding_matrix, \"binary_crossentropy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
