{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import pickle\n",
    "import random as rn\n",
    "import warnings\n",
    "from importlib import reload\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.fasttext import FastText\n",
    "from IPython.display import display\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, ndcg_score, \\\n",
    "        label_ranking_average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import data\n",
    "import models\n",
    "import preprocessing\n",
    "\n",
    "seed = 42\n",
    "sns.set()\n",
    "\n",
    "def reset_seed():\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "    np.random.seed(seed)\n",
    "    rn.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose notebook version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version = \"tokenized_cased\"\n",
    "# version = \"tokenized_no_sw_no_punct\"\n",
    "version = \"tokenized_lemmatized_no_sw_no_punct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Extracting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299773,)\n",
      "(299773, 126)\n",
      "Toronto stocks end higher after volatile session. CHANGE\t\t\t\t    CHANGE TSE\t  5900.37    +50.15   HI 5900.37\t    LO  5840.29 DJI\t  6611.05    +27.57   GOLD (LONDON)   US$350.00 +1.90 FTSE100    4248.10    -64.80   GOLD (NY-COMEX) US$354.80 +0.70 NIKKEI    17869.59   -133.81   LME CASH NICKEL US$7659   +99.0 CANDLR\t1.3883\t\t LME CASH ALUM   US$1602.0  -4.0 CAN 30-YR   107.41     -0.15   BRENT CRUDE     US$19.09  -0.27 --------------------MARKET COMMENT---------------------------- * Toronto stocks ended higher on Tuesday, buoyed by strength in golds and banking * Computer problems due to heavy trading in Bre-X Minerals hampered session * 84 million shares traded Toronto's key stock index ended higher on Tuesday as the saga of Bre-X Minerals Ltd and its Indonesian gold find continued to dominate Canada's biggest stock market. The TSE 300 Index climbed 50.15 points to close at 5900.37 in heavy turnover of 84.07 million shares worth C$1.4 billion. But the overall market was mixed with declining issues narrowly outpacing advances 476 to 464. 298 issues were flat. Frantic trading in Bre-X collapsed the TSE's computer trading system earlier in the day, forcing the exchange to halt trading in the stock before the market closed. Shares in the Calgary-based gold prospector were halted for a statement by the company this morning. When it resumed, a whopping 7.7 million shares changed hands in the first 22 minutes of trading before the system crashed. Bre-X closed up 1.35 at 3.85. It was the first time Bre-X traded since investors lopped nearly C$3 billion off its stock market value last Thursday. TSE officials said the trading problems were due to old technology which will be replaced. On the Montreal Exchange, Bre-X closed up 0.81 at 3.50 on 9.8 million shares. Analysts predicted more volatility for Bre-X shares this week. \"The question of what Bre-X will release over the next few days will be important to the market,\" said Josef Schachter, of Schachter Asset Management Inc. The gold sector rose nearly 136 points, leading 12 of 14 sub-indices higher. Other strong groups included financial services, consumer products, energy and transportation. The TSE posted minor losses in forestry and real estate. --- HOT STOCKS --- * Among bank shares, Bank of Nova Scotia rose 0.65 to 51.50 on 2.1 million shares, while Canadian Imperial Bank of Commerce added 0.50 to 31.80 on 2.1 million shares. ((Reuters Toronto Bureau (416) 941-8100))\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# data.extract_data(extraction_dir=\"train\",\n",
    "#                   data_dir=\"data\",\n",
    "#                   data_zip_name=\"reuters-training-corpus.zip\")\n",
    "\n",
    "train_df = pd.read_pickle(\"train/data.pkl\")\n",
    "\n",
    "# train_df = data.get_docs_labels(\"train/REUTERS_CORPUS_2\")\n",
    "# train_df.to_pickle(\"train/data.pkl\")\n",
    "\n",
    "train_docs = train_df[\"doc\"].values\n",
    "n_train = train_docs.shape[0]\n",
    "train_labels = np.array(train_df[\"labels\"].tolist())\n",
    "n_labels = len(data.CODEMAP)\n",
    "\n",
    "# extract test_docs here\n",
    "\n",
    "print(train_docs.shape)\n",
    "print(train_labels.shape)\n",
    "print(train_docs[2])\n",
    "print(train_labels[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocessing the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toronto stock end high volatile session change change tse 5900.37 +50.15 hi 5900.37 lo 5840.29 dji 6611.05 +27.57 gold london us$ 350.00 +1.90 ftse100 4248.10 -64.80 gold ny comex us$ 354.80 +0.70 nikkei 17869.59 -133.81 lme cash nickel us$ 7659 +99.0 candlr 1.3883 lme cash alum us$ 1602.0 -4.0 30-yr 107.41 -0.15 brent crude us$ 19.09 -0.27 --------------------market comment---------------------------- toronto stock end higher tuesday buoy strength gold banking computer problem heavy trading bre x minerals hamper session 84 million share trade toronto key stock index end higher tuesday saga bre x minerals ltd indonesian gold find continue dominate canada big stock market tse 300 index climb 50.15 point close 5900.37 heavy turnover 84.07 million share worth c$ 1.4 billion overall market mix decline issue narrowly outpace advance 476 464 298 issue flat frantic trading bre x collapse tse computer trading system earlier day force exchange halt trading stock market close share calgary base gold prospector halt statement company morning resume whopping 7.7 million share change hand 22 minute trading system crash bre x close 1.35 3.85 time bre x trade investor lop nearly c$ 3 billion stock market value thursday tse official say trading problem old technology replace montreal exchange bre x close 0.81 3.50 9.8 million share analyst predict volatility bre x share week question bre x release day important market say josef schachter schachter asset management inc. gold sector rise nearly 136 point lead 12 14 sub index high strong group include financial service consumer product energy transportation tse post minor loss forestry real estate hot stock bank share bank nova scotia rise 0.65 51.50 2.1 million share canadian imperial bank commerce add 0.50 31.80 2.1 million share reuters toronto bureau 416 941 8100\n"
     ]
    }
   ],
   "source": [
    "path_to_preprocessed_train_docs = f\"train/preprocessed_docs_{version}.pkl\"\n",
    "\n",
    "try:\n",
    "    with open(path_to_preprocessed_train_docs, \"rb\") as f:\n",
    "        preprocessed_train_docs = pickle.load(f)\n",
    "except:\n",
    "    preprocessed_train_docs = preprocessing.preprocess_corpus(train_docs)\n",
    "    with open(path_to_preprocessed_train_docs, \"wb\") as f:\n",
    "        pickle.dump(preprocessed_train_docs, f)\n",
    "\n",
    "print(preprocessed_train_docs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_preprocessed_test_docs = f\"test/preprocessed_docs_{version}.pkl\"\n",
    "\n",
    "# try:\n",
    "#     with open(path_to_preprocessed_test_docs, \"rb\") as f:\n",
    "#         preprocessed_test_docs = pickle.load(f)\n",
    "# except:\n",
    "#     preprocessed_test_docs = preprocessing.preprocess_corpus(test_docs)\n",
    "#     with open(path_to_preprocessed_test_docs, \"wb\") as f:\n",
    "#         pickle.dump(preprocessed_test_docs, f)\n",
    "\n",
    "# print(preprocessed_test_docs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing the documents as token index sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = preprocessed_train_docs # add preprocessed_test_docs\n",
    "n_vocabulary = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648464\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=n_vocabulary, filters=\"\", lower=False)\n",
    "tokenizer.fit_on_texts(docs)\n",
    "word_idx = tokenizer.word_index\n",
    "if n_vocabulary is None:\n",
    "    n_vocabulary = len(word_idx) + 1\n",
    "\n",
    "print(n_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "(299773, 512)\n",
      "[  1610     24     17     19   2090    436    114    114   6746 188917\n",
      " 327927   4443 188917   5714 327928  21934 142487 232206    240    141\n",
      "    492  16347 101127  42844 327929 327930    240   2564   2406    492\n",
      " 188918  52097   2264 327931 160780   1386    263   1863    492 327932\n",
      " 327933  17989 160781   1386    263  15720    492 327934  10896   7925\n",
      "  94597  25805    914    407    492  30933  35331  24629  27525   1610\n",
      "     24     17    700     37   3599    827    240    567    674    327\n",
      "    617    162   2578   1520   4945   4521    436   3271      5      7\n",
      "     20   1610    328     24     75     17    700     37   7262   2578\n",
      "   1520   4945    151   1456    240    314    112   1549    488    198]\n"
     ]
    }
   ],
   "source": [
    "n_sequence = 512\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(docs)\n",
    "if n_sequence is None:\n",
    "    n_sequence = max([len(s) for s in sequences])\n",
    "sequence_lengths = [min(len(s), n_sequence) for s in sequences]\n",
    "sequences = pad_sequences(sequences,\n",
    "                          maxlen=n_sequence,\n",
    "                          padding=\"post\",\n",
    "                          truncating=\"post\")\n",
    "\n",
    "print(n_sequence)\n",
    "print(sequences.shape)\n",
    "print(sequences[2][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_lengths = [len(doc.split()) for doc in docs]\n",
    "\n",
    "sns.distplot(doc_lengths,\n",
    "             bins=np.arange(0, 2500, 25),\n",
    "             kde=False,\n",
    "             label=\"documents\")\n",
    "sns.distplot(sequence_lengths,\n",
    "             bins=np.arange(0, 2500, 25),\n",
    "             kde=False,\n",
    "             label=\"sequences\")\n",
    "total_word_coverage = np.round(np.sum(sequence_lengths) / np.sum(doc_lengths), 3)\n",
    "plt.title(f\"n_vocabulary={n_vocabulary}, n_sequence={n_sequence},\\n\"\n",
    "          f\"total_word_coverage={total_word_coverage}\")\n",
    "plt.xlim(0, 1550)\n",
    "plt.xlabel(\"length\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_embedding = 300 # 300 required by pretrained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648463\n",
      "['say', '$', 'percent', 'year', 'million', 'market', 'share', 'bank', 'company', 'new', 'price', 'n', 'rate', 'billion', 'government', 'u.s.', 'end', 'week', 'high', 'trade', 'month', 'rise', 'expect', 'stock', '1997', 'sale', 'june', '1', 'net', 'newsroom', 'group', 'pct', 'day', 'state', 'report', 'close', 'tuesday', '1996', 'wednesday', 'official', 'july', 'low', 'thursday', 'monday', 'point', 'friday', 'bond', 'plan', 'issue', 'minister', 'trader', 'fall', 'dollar', '2', 'tell', 'interest', 'profit', '=', 'vs', 'time', 'yen', 'income', 'loss', 'analyst', 'add', 'quarter', 'result', 'country', 'oil', 'total', 'president', 'firm', 'lead', 'april', 'index', 'cent', 'see', 'tonne', '10', 'march', 'include', 'foreign', 'increase', 'sell', 'hold', '30', 'business', 'dealer', 'note', 'central', 'second', 'people', 'european', 'tax', 'f', 'future', 'buy', 'term', 'follow', 'party']\n"
     ]
    }
   ],
   "source": [
    "reset_seed()\n",
    "\n",
    "# ft_path = f\"data/fasttext_{version}.model\"\n",
    "ft_path = f\"train/fasttext_{version}.model\"\n",
    "\n",
    "try:\n",
    "    ft = FastText.load(ft_path)\n",
    "except:\n",
    "    ft = FastText(sentences=[doc.split() for doc in docs], size=n_embedding,\n",
    "                  min_count=1, workers=cpu_count(), seed=seed)\n",
    "    ft.save(ft_path)\n",
    "\n",
    "print(len(list(ft.wv.vocab)))\n",
    "print(ft.wv.index2entity[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648463\n",
      "['say', '$', 'percent', 'year', 'million', 'market', 'share', 'bank', 'company', 'new', 'price', 'n', 'rate', 'billion', 'government', 'u.s.', 'end', 'week', 'high', 'trade', 'month', 'rise', 'expect', 'stock', '1997', 'sale', 'june', '1', 'net', 'newsroom', 'group', 'pct', 'day', 'state', 'report', 'close', 'tuesday', '1996', 'wednesday', 'official', 'july', 'low', 'thursday', 'monday', 'point', 'friday', 'bond', 'plan', 'issue', 'minister', 'trader', 'fall', 'dollar', '2', 'tell', 'interest', 'profit', '=', 'vs', 'time', 'yen', 'income', 'loss', 'analyst', 'add', 'quarter', 'result', 'country', 'oil', 'total', 'president', 'firm', 'lead', 'april', 'index', 'cent', 'see', 'tonne', '10', 'march', 'include', 'foreign', 'increase', 'sell', 'hold', '30', 'business', 'dealer', 'note', 'central', 'second', 'people', 'european', 'tax', 'f', 'future', 'buy', 'term', 'follow', 'party']\n"
     ]
    }
   ],
   "source": [
    "reset_seed()\n",
    "\n",
    "# w2v_path = f\"data/w2v_{version}.model\"\n",
    "w2v_path = f\"train/w2v_{version}.model\"\n",
    "\n",
    "try:\n",
    "    w2v = Word2Vec.load(w2v_path)\n",
    "except:\n",
    "    w2v = Word2Vec(sentences=[doc.split() for doc in docs], size=n_embedding,\n",
    "                   min_count=1, workers=cpu_count(), seed=seed)\n",
    "    w2v.save(w2v_path)\n",
    "\n",
    "print(len(list(w2v.wv.vocab)))\n",
    "print(w2v.wv.index2entity[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(fname, skip_first):\n",
    "    embedding_idx = {}\n",
    "    with open(fname, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i == 0 and skip_first:\n",
    "                continue\n",
    "            vals = line.rstrip().split()\n",
    "            token = \"\".join(vals[:-300])\n",
    "            embedding = np.array(vals[-300:], dtype=np.float32)\n",
    "            embedding_idx[token] = embedding\n",
    "    return embedding_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', 'the', '.', 'and', 'to', 'of', 'a', 'in', 'is', 'for', 'that', 'I', 'it', 'on', 'with', ')', ':', '\"', '(', 'The', 'you', 'was', 'are', 'or', 'this', 'as', 'have', 'at', 'from', '!', \"'s\", 'but', 'by', 'not', '?', 'your', 'all', '/', 'be', 'we', 'my', 'one', '-', 'will', 'they', 'so', 'which', '”', '“', 'has', '...', 'just', 'he', 'their', 'can', 'about', 'his', 'our', ';', 'when', 'more', 'had', 'do', 'some', 'time', 'like', 'also', 'there', 'them', 'get', 'what', 'out', \"'\", 'me', 'her', 'an', 'were', 'This', 'It', 'up', 'would', 'if', 'who', 'new', 'only', 'A', '–', 'people', 'any', 'We', 'make', 'other', 'In', 'then', 'its', 'use', 'said', 'now', 'no', 'first']\n"
     ]
    }
   ],
   "source": [
    "ft_pretrained = load_embeddings(\"data/crawl-300d-2M.vec\", skip_first=True)\n",
    "\n",
    "token_iter = iter(ft_pretrained)\n",
    "print([next(token_iter) for i in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', 'the', '.', 'and', 'to', 'of', 'a', 'in', '\"', 'is', 'for', ':', 'i', ')', 'that', '(', 'you', 'it', 'on', '-', 'with', \"'s\", 'this', 'by', 'are', 'at', 'as', 'be', 'from', 'have', 'was', 'or', 'your', 'not', '...', 'we', '!', 'but', '?', 'all', 'will', 'an', 'my', 'can', 'they', \"n't\", 'do', 'he', 'more', 'if', 'one', 'has', '|', 'so', 'about', 'new', 'what', 'his', 'there', 'up', 'out', ';', 'their', 'our', \"'\", 'like', 'when', '$', 'just', 'time', '&', 'me', 'which', 'who', 'no', 'would', '/', '1', 'some', 'get', '[', ']', 'also', 'other', 'how', 'may', 'had', 'am', 'been', '2', 'her', 'were', 'them', 'people', 'she', 'any', 'now', 'only', 'pm', 'first']\n"
     ]
    }
   ],
   "source": [
    "if version == \"tokenized_cased\":\n",
    "    glove_pretrained = load_embeddings(\"data/glove.840B.300d.txt\", skip_first=False)\n",
    "else:\n",
    "    glove_pretrained = load_embeddings(\"data/glove.42B.300d.txt\", skip_first=False)\n",
    "    \n",
    "token_iter = iter(glove_pretrained)\n",
    "print([next(token_iter) for i in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_embedding_matrix(embedding_model):\n",
    "    embedding_matrix = np.zeros((n_vocabulary, n_embedding))\n",
    "    unknown_token_count = 0\n",
    "    for token, i in word_idx.items():\n",
    "        if i >= n_vocabulary:\n",
    "            continue\n",
    "        if token in embedding_model:\n",
    "            embedding_matrix[i] = embedding_model[token]\n",
    "        else:\n",
    "            unknown_token_count += 1\n",
    "\n",
    "    print(unknown_token_count)\n",
    "    print(embedding_matrix.shape)\n",
    "    print(embedding_matrix[1][:20])\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(648464, 300)\n",
      "[ 2.4902842   1.52035058  5.09899616  1.2855531  -5.56696224  1.30260634\n",
      " -0.25823388  1.54942441 -5.83403111 -3.42612696 -1.29245317  0.07350405\n",
      "  3.97383833 -0.56737322  0.71295166  0.28651431  2.2289803   0.64537144\n",
      " -1.12739778  3.30533552]\n"
     ]
    }
   ],
   "source": [
    "ft_embedding_matrix = create_embedding_matrix(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(648464, 300)\n",
      "[ 1.11789823  0.90454006 -0.0740659   1.98215711  0.78678864  0.6198563\n",
      "  0.36847508  2.22324443 -0.65470326  0.1890929  -0.50569427 -0.48286599\n",
      " -0.48370102  0.16942278 -0.49846452  0.35915473 -1.1099689   0.31582713\n",
      "  2.01565337  2.2916019 ]\n"
     ]
    }
   ],
   "source": [
    "w2v_embedding_matrix = create_embedding_matrix(w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502305\n",
      "(648464, 300)\n",
      "[ 0.0597     -0.19410001 -0.0321     -0.2568      0.0183      0.13240001\n",
      "  0.2368      0.0721      0.0786      0.1144      0.0029      0.1675\n",
      "  0.2789     -0.0373      0.027      -0.0198      0.014       0.0152\n",
      " -0.066       0.0892    ]\n"
     ]
    }
   ],
   "source": [
    "ft_pretrained_embedding_matrix = create_embedding_matrix(ft_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411644\n",
      "(648464, 300)\n",
      "[-0.014566    0.0070719  -0.011097   -0.19108    -0.14068     0.30050999\n",
      " -3.81360006  0.17456999  0.038443   -0.88959002  0.26578     0.23799001\n",
      " -0.12661    -0.21301    -0.2097      0.24066     0.25748    -0.39872\n",
      " -0.058705   -0.0088072 ]\n"
     ]
    }
   ],
   "source": [
    "glove_pretrained_embedding_matrix = create_embedding_matrix(glove_pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = None\n",
    "x_train, y_train = shuffle(sequences[:n_train],\n",
    "                           train_labels,\n",
    "                           random_state=seed,\n",
    "                           n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-evaluating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_evaluate(model_initializer, batch_size=256, model_params={}):\n",
    "    model_initializer(n_vocabulary, n_embedding, n_sequence, n_labels,\n",
    "                      **model_params).summary()\n",
    "\n",
    "    cv_scores = []\n",
    "    best_model = None\n",
    "    best_f1_micro = 0\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=5, random_state=seed)\n",
    "    for train, val in mskf.split(x_train, y_train):\n",
    "        model = model_initializer(n_vocabulary, n_embedding, n_sequence, n_labels,\n",
    "                                  **model_params)\n",
    "        es = EarlyStopping(patience=5, verbose=1, restore_best_weights=True)\n",
    "        history = model.fit(x_train[train],\n",
    "                            y_train[train],\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=100,\n",
    "                            verbose=1,\n",
    "                            validation_data=(x_train[val], y_train[val]),\n",
    "                            callbacks=[es])\n",
    "\n",
    "        y_pred_prob = model.predict(x_train[val], batch_size=batch_size, verbose=1)\n",
    "        y_pred = np.round(y_pred_prob)\n",
    "\n",
    "        scores = {}\n",
    "        scores[\"accuracy\"] = accuracy_score(y_train[val], y_pred)\n",
    "        scores[\"F1 (macro)\"] = f1_score(y_train[val], y_pred, average=\"macro\")\n",
    "        scores[\"F1 (micro)\"] = f1_score(y_train[val], y_pred, average=\"micro\")\n",
    "        scores[\"LRAP\"] = label_ranking_average_precision_score(y_train[val],\n",
    "                                                               y_pred_prob)\n",
    "        scores[\"NDCG\"] = ndcg_score(y_train[val], y_pred_prob)\n",
    "        cv_scores.append(scores)\n",
    "        print(scores)\n",
    "        \n",
    "        if scores[\"F1 (micro)\"] > best_f1_micro:\n",
    "            best_f1_micro = scores[\"F1 (micro)\"]\n",
    "            best_model = model\n",
    "\n",
    "#     best_model.save(f\"best_models/{model_initializer.__name__}_{version}.h5\")\n",
    "    best_model.save(f\"best_models_train/{model_initializer.__name__}_{version}.h5\")\n",
    "\n",
    "    cv_scores_df = pd.DataFrame(cv_scores)\n",
    "    display(cv_scores_df)\n",
    "    print(cv_scores_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 512, 300)          194539200 \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 511, 400)          240400    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 511, 400)          1600      \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 511, 400)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 255, 400)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 255, 400)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 254, 500)          400500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 254, 500)          2000      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 254, 500)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 127, 500)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 127, 500)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 512)               1550336   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 126)               64638     \n",
      "=================================================================\n",
      "Total params: 196,798,674\n",
      "Trainable params: 2,257,674\n",
      "Non-trainable params: 194,541,000\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Epoch 1/100\n",
      " 78/937 [=>............................] - ETA: 32:48 - loss: 0.1081"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-0ad3f3d8db49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m cross_evaluate(models.cnn_bi_lstm_1, model_params={\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"filters_1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"filters_2\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"binary_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \"embedding_matrix\": w2v_embedding_matrix})\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-ced60443c910>\u001b[0m in \u001b[0;36mcross_evaluate\u001b[0;34m(model_initializer, batch_size, model_params)\u001b[0m\n\u001b[1;32m     17\u001b[0m                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                             callbacks=[es])\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0my_pred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.cnn_bi_lstm_1, model_params={\n",
    "    \"filters_1\": 400, \"filters_2\": 500, \"loss\": \"binary_crossentropy\",\n",
    "    \"embedding_matrix\": w2v_embedding_matrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.cnn_bi_lstm_1, model_params={\n",
    "    \"filters_1\": 400, \"filters_2\": 500, \"loss\": \"mean_squared_error\",\n",
    "    \"embedding_matrix\": w2v_embedding_matrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.cnn_bi_lstm_1, model_params={\n",
    "    \"filters_1\": 400, \"filters_2\": 500, \"loss\": \"binary_crossentropy\",\n",
    "    \"embedding_matrix\": glove_pretrained_embedding_matrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.cnn_bi_lstm_1, model_params={\n",
    "    \"filters_1\": 400, \"filters_2\": 500, \"loss\": \"mean_squared_error\",\n",
    "    \"embedding_matrix\": glove_pretrained_embedding_matrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.cnn_bi_lstm_1, model_params={\n",
    "    \"filters_1\": 400, \"filters_2\": 500, \"loss\": \"binary_crossentropy\",\n",
    "    \"embedding_matrix\": ft_embedding_matrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.cnn_bi_lstm_1, model_params={\n",
    "    \"filters_1\": 400, \"filters_2\": 500, \"loss\": \"mean_squared_error\",\n",
    "    \"embedding_matrix\": ft_embedding_matrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.split_cnn_bi_lstm_2, model_params={\n",
    "    \"filters_1\": 400, \"filters_2\": 500, \"loss\": \"binary_crossentropy\",\n",
    "    \"embedding_matrix_1\": w2v_embedding_matrix,\n",
    "    \"embedding_matrix_2\": glove_pretrained_embedding_matrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.split_cnn_bi_lstm_2, model_params={\n",
    "    \"filters_1\": 400, \"filters_2\": 500, \"loss\": \"mean_squared_error\",\n",
    "    \"embedding_matrix_1\": w2v_embedding_matrix,\n",
    "    \"embedding_matrix_2\": glove_pretrained_embedding_matrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.split_cnn_bi_lstm_2, model_params={\n",
    "    \"filters_1\": 400, \"filters_2\": 500, \"loss\": \"binary_crossentropy\",\n",
    "    \"embedding_matrix_1\": w2v_embedding_matrix,\n",
    "    \"embedding_matrix_2\": ft_embedding_matrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.split_cnn_bi_lstm_2, model_params={\n",
    "    \"filters_1\": 400, \"filters_2\": 500, \"loss\": \"mean_squared_error\",\n",
    "    \"embedding_matrix_1\": w2v_embedding_matrix,\n",
    "    \"embedding_matrix_2\": ft_embedding_matrix})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
