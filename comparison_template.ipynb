{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import pickle\n",
    "import random as rn\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from importlib import reload\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.fasttext import FastText\n",
    "from IPython.display import display\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, ndcg_score, \\\n",
    "        label_ranking_average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import data\n",
    "import models\n",
    "import preprocessing\n",
    "\n",
    "seed = 42\n",
    "sns.set()\n",
    "\n",
    "def reset_seed():\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "    np.random.seed(seed)\n",
    "    rn.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose notebook version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version = \"tokenized_cased\"\n",
    "# version = \"tokenized_no_sw_no_punct\"\n",
    "version = \"tokenized_lemmatized_no_sw_no_punct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Extracting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data.extract_data(extraction_dir=\"train\",\n",
    "#                   data_dir=\"data\",\n",
    "#                   data_zip_name=\"reuters-training-corpus.zip\")\n",
    "\n",
    "train_df = pd.read_pickle(\"train/data.pkl\")\n",
    "\n",
    "# train_df = data.get_docs_labels(\"train/REUTERS_CORPUS_2\")\n",
    "# train_df.to_pickle(\"train/data.pkl\")\n",
    "\n",
    "train_docs = train_df[\"doc\"].values\n",
    "n_train = train_docs.shape[0]\n",
    "train_labels = np.array(train_df[\"labels\"].tolist())\n",
    "n_labels = len(data.CODEMAP)\n",
    "\n",
    "# extract test_docs here\n",
    "\n",
    "print(train_docs.shape)\n",
    "print(train_labels.shape)\n",
    "print(train_docs[2])\n",
    "print(train_labels[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocessing the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path_to_preprocessed_train_docs = f\"train/preprocessed_docs_{version}.pkl\"\n",
    "\n",
    "try:\n",
    "    with open(path_to_preprocessed_train_docs, \"rb\") as f:\n",
    "        preprocessed_train_docs = pickle.load(f)\n",
    "except:\n",
    "    preprocessed_train_docs = preprocessing.preprocess_corpus(train_docs)\n",
    "    with open(path_to_preprocessed_train_docs, \"wb\") as f:\n",
    "        pickle.dump(preprocessed_train_docs, f)\n",
    "\n",
    "print(preprocessed_train_docs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_preprocessed_test_docs = f\"test/preprocessed_docs_{version}.pkl\"\n",
    "\n",
    "# try:\n",
    "#     with open(path_to_preprocessed_test_docs, \"rb\") as f:\n",
    "#         preprocessed_test_docs = pickle.load(f)\n",
    "# except:\n",
    "#     preprocessed_test_docs = preprocessing.preprocess_corpus(test_docs)\n",
    "#     with open(path_to_preprocessed_test_docs, \"wb\") as f:\n",
    "#         pickle.dump(preprocessed_test_docs, f)\n",
    "\n",
    "# print(preprocessed_test_docs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing the documents as token index sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = preprocessed_train_docs # add preprocessed_test_docs\n",
    "n_vocabulary = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=n_vocabulary, filters=\"\", lower=False)\n",
    "tokenizer.fit_on_texts(docs)\n",
    "word_idx = tokenizer.word_index\n",
    "if n_vocabulary is None:\n",
    "    n_vocabulary = len(word_idx) + 1 # use index 0 for padding\n",
    "\n",
    "print(n_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_sequence = 512\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(docs)\n",
    "if n_sequence is None:\n",
    "    n_sequence = max([len(s) for s in sequences])\n",
    "sequence_lengths = [min(len(s), n_sequence) for s in sequences]\n",
    "sequences = pad_sequences(sequences,\n",
    "                          maxlen=n_sequence,\n",
    "                          padding=\"post\",\n",
    "                          truncating=\"post\")\n",
    "\n",
    "print(n_sequence)\n",
    "print(sequences.shape)\n",
    "print(sequences[2][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "doc_lengths = [len(doc.split()) for doc in docs]\n",
    "\n",
    "sns.distplot(doc_lengths,\n",
    "             bins=np.arange(0, 2500, 25),\n",
    "             kde=False,\n",
    "             label=\"documents\")\n",
    "sns.distplot(sequence_lengths,\n",
    "             bins=np.arange(0, 2500, 25),\n",
    "             kde=False,\n",
    "             label=\"sequences\")\n",
    "total_word_coverage = np.round(np.sum(sequence_lengths) / np.sum(doc_lengths), 3)\n",
    "plt.title(f\"n_vocabulary={n_vocabulary}, n_sequence={n_sequence},\\n\"\n",
    "          f\"total_word_coverage={total_word_coverage}\")\n",
    "plt.xlim(0, 1550)\n",
    "plt.xlabel(\"length\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_embedding = 300 # 300 required by pretrained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed()\n",
    "\n",
    "# ft_path = f\"data/fasttext_{version}.model\"\n",
    "ft_path = f\"train/fasttext_{version}.model\"\n",
    "\n",
    "try:\n",
    "    ft = FastText.load(ft_path)\n",
    "except:\n",
    "    ft = FastText(sentences=[doc.split() for doc in docs], size=n_embedding,\n",
    "                  min_count=1, workers=cpu_count(), seed=seed)\n",
    "    ft.save(ft_path)\n",
    "\n",
    "print(len(list(ft.wv.vocab)))\n",
    "print(ft.wv.index2entity[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reset_seed()\n",
    "\n",
    "# w2v_path = f\"data/w2v_{version}.model\"\n",
    "w2v_path = f\"train/w2v_{version}.model\"\n",
    "\n",
    "try:\n",
    "    w2v = Word2Vec.load(w2v_path)\n",
    "except:\n",
    "    w2v = Word2Vec(sentences=[doc.split() for doc in docs], size=n_embedding,\n",
    "                   min_count=1, workers=cpu_count(), seed=seed)\n",
    "    w2v.save(w2v_path)\n",
    "\n",
    "print(len(list(w2v.wv.vocab)))\n",
    "print(w2v.wv.index2entity[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(fname, skip_first):\n",
    "    embedding_idx = {}\n",
    "    with open(fname, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i == 0 and skip_first:\n",
    "                continue\n",
    "            vals = line.rstrip().split()\n",
    "            token = \"\".join(vals[:-300])\n",
    "            embedding = np.array(vals[-300:], dtype=np.float32)\n",
    "            embedding_idx[token] = embedding\n",
    "    return embedding_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_pretrained = load_embeddings(\"data/crawl-300d-2M.vec\", skip_first=True)\n",
    "\n",
    "token_iter = iter(ft_pretrained)\n",
    "print([next(token_iter) for i in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if version == \"tokenized_cased\":\n",
    "    glove_pretrained = load_embeddings(\"data/glove.840B.300d.txt\", skip_first=False)\n",
    "else:\n",
    "    glove_pretrained = load_embeddings(\"data/glove.42B.300d.txt\", skip_first=False)\n",
    "    \n",
    "token_iter = iter(glove_pretrained)\n",
    "print([next(token_iter) for i in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_embedding_matrix(embedding_model):\n",
    "    embedding_matrix = np.zeros((n_vocabulary, n_embedding))\n",
    "    unknown_token_count = 0\n",
    "    for token, i in word_idx.items():\n",
    "        if i >= n_vocabulary:\n",
    "            continue\n",
    "        if token in embedding_model:\n",
    "            embedding_matrix[i] = embedding_model[token]\n",
    "        else:\n",
    "            unknown_token_count += 1\n",
    "\n",
    "    print(unknown_token_count)\n",
    "    print(embedding_matrix.shape)\n",
    "    print(embedding_matrix[1][:20])\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_embedding_matrix = create_embedding_matrix(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_embedding_matrix = create_embedding_matrix(w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_pretrained_embedding_matrix = create_embedding_matrix(ft_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_pretrained_embedding_matrix = create_embedding_matrix(glove_pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = None\n",
    "x_train, y_train = shuffle(sequences[:n_train],\n",
    "                           train_labels,\n",
    "                           random_state=seed,\n",
    "                           n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-evaluating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_evaluate(model_initializer, batch_size=256, model_params={}):\n",
    "    model_initializer(n_vocabulary, n_embedding, n_sequence, n_labels,\n",
    "                      **model_params).summary()\n",
    "\n",
    "    cv_scores = []\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=5, random_state=seed)\n",
    "    for train, val in mskf.split(x_train, y_train):\n",
    "        model = model_initializer(n_vocabulary, n_embedding, n_sequence, n_labels,\n",
    "                                  **model_params)\n",
    "        es = EarlyStopping(patience=10, verbose=1, restore_best_weights=True)\n",
    "        history = model.fit(x_train[train],\n",
    "                            y_train[train],\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=100,\n",
    "                            verbose=1,\n",
    "                            validation_data=(x_train[val], y_train[val]),\n",
    "                            callbacks=[es])\n",
    "\n",
    "        y_pred_prob = model.predict(x_train[val], batch_size=batch_size, verbose=1)\n",
    "        y_pred = np.round(y_pred_prob)\n",
    "\n",
    "        scores = {}\n",
    "        scores[\"accuracy\"] = accuracy_score(y_train[val], y_pred)\n",
    "        scores[\"F1 (macro)\"] = f1_score(y_train[val], y_pred, average=\"macro\")\n",
    "        scores[\"F1 (micro)\"] = f1_score(y_train[val], y_pred, average=\"micro\")\n",
    "        scores[\"LRAP\"] = label_ranking_average_precision_score(y_train[val],\n",
    "                                                               y_pred_prob)\n",
    "        scores[\"NDCG\"] = ndcg_score(y_train[val], y_pred_prob)\n",
    "        scores[\"timestamp\"] = round(datetime.timestamp(datetime.now()))\n",
    "        cv_scores.append(scores)\n",
    "        print(scores)\n",
    "\n",
    "#         model.save(f\"best_models/{model_initializer.__name__}_{version}_\" +\n",
    "#                    f\"{scores['timestamp']}_\" +\n",
    "#                    f\"{np.round(scores['F1 (micro)'], 6)}\")\n",
    "        model.save(f\"best_models_train/{model_initializer.__name__}_{version}_\" +\n",
    "                   f\"{scores['timestamp']}_\" +\n",
    "                   f\"{np.round(scores['F1 (micro)'], 6)}\")\n",
    "\n",
    "    cv_scores_df = pd.DataFrame(cv_scores)\n",
    "    display(cv_scores_df)\n",
    "    print(cv_scores_df.drop(\"timestamp\", axis=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.cnn_bi_lstm_1, model_params={\n",
    "    \"filters_1\": 400, \"filters_2\": 500, \"loss\": \"binary_crossentropy\",\n",
    "    \"embedding_matrix\": w2v_embedding_matrix})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
