{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import pickle\n",
    "import random as rn\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from importlib import reload\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.fasttext import FastText\n",
    "from IPython.display import display\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, ndcg_score, \\\n",
    "        label_ranking_average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import data\n",
    "import models\n",
    "import preprocessing\n",
    "\n",
    "seed = 42\n",
    "sns.set()\n",
    "\n",
    "def reset_seed():\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "    np.random.seed(seed)\n",
    "    rn.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose notebook version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"tokenized_cased\"\n",
    "# version = \"tokenized_no_sw_no_punct\"\n",
    "# version = \"tokenized_lemmatized_no_sw_no_punct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Extracting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299773,)\n",
      "(299773, 126)\n",
      "Toronto stocks end higher after volatile session. CHANGE\t\t\t\t    CHANGE TSE\t  5900.37    +50.15   HI 5900.37\t    LO  5840.29 DJI\t  6611.05    +27.57   GOLD (LONDON)   US$350.00 +1.90 FTSE100    4248.10    -64.80   GOLD (NY-COMEX) US$354.80 +0.70 NIKKEI    17869.59   -133.81   LME CASH NICKEL US$7659   +99.0 CANDLR\t1.3883\t\t LME CASH ALUM   US$1602.0  -4.0 CAN 30-YR   107.41     -0.15   BRENT CRUDE     US$19.09  -0.27 --------------------MARKET COMMENT---------------------------- * Toronto stocks ended higher on Tuesday, buoyed by strength in golds and banking * Computer problems due to heavy trading in Bre-X Minerals hampered session * 84 million shares traded Toronto's key stock index ended higher on Tuesday as the saga of Bre-X Minerals Ltd and its Indonesian gold find continued to dominate Canada's biggest stock market. The TSE 300 Index climbed 50.15 points to close at 5900.37 in heavy turnover of 84.07 million shares worth C$1.4 billion. But the overall market was mixed with declining issues narrowly outpacing advances 476 to 464. 298 issues were flat. Frantic trading in Bre-X collapsed the TSE's computer trading system earlier in the day, forcing the exchange to halt trading in the stock before the market closed. Shares in the Calgary-based gold prospector were halted for a statement by the company this morning. When it resumed, a whopping 7.7 million shares changed hands in the first 22 minutes of trading before the system crashed. Bre-X closed up 1.35 at 3.85. It was the first time Bre-X traded since investors lopped nearly C$3 billion off its stock market value last Thursday. TSE officials said the trading problems were due to old technology which will be replaced. On the Montreal Exchange, Bre-X closed up 0.81 at 3.50 on 9.8 million shares. Analysts predicted more volatility for Bre-X shares this week. \"The question of what Bre-X will release over the next few days will be important to the market,\" said Josef Schachter, of Schachter Asset Management Inc. The gold sector rose nearly 136 points, leading 12 of 14 sub-indices higher. Other strong groups included financial services, consumer products, energy and transportation. The TSE posted minor losses in forestry and real estate. --- HOT STOCKS --- * Among bank shares, Bank of Nova Scotia rose 0.65 to 51.50 on 2.1 million shares, while Canadian Imperial Bank of Commerce added 0.50 to 31.80 on 2.1 million shares. ((Reuters Toronto Bureau (416) 941-8100))\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# data.extract_data(extraction_dir=\"train\",\n",
    "#                   data_dir=\"data\",\n",
    "#                   data_zip_name=\"reuters-training-corpus.zip\")\n",
    "\n",
    "train_df = pd.read_pickle(\"train/data.pkl\")\n",
    "\n",
    "# train_df = data.get_docs_labels(\"train/REUTERS_CORPUS_2\")\n",
    "# train_df.to_pickle(\"train/data.pkl\")\n",
    "\n",
    "train_docs = train_df[\"doc\"].values\n",
    "n_train = train_docs.shape[0]\n",
    "train_labels = np.array(train_df[\"labels\"].tolist())\n",
    "n_labels = len(data.CODEMAP)\n",
    "\n",
    "# extract test_docs here\n",
    "\n",
    "print(train_docs.shape)\n",
    "print(train_labels.shape)\n",
    "print(train_docs[2])\n",
    "print(train_labels[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocessing the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toronto stocks end higher after volatile session . CHANGE CHANGE TSE 5900.37 +50.15 HI 5900.37 LO 5840.29 DJI 6611.05 +27.57 GOLD ( LONDON ) US$ 350.00 +1.90 FTSE100 4248.10 -64.80 GOLD ( NY - COMEX ) US$ 354.80 +0.70 NIKKEI 17869.59 -133.81 LME CASH NICKEL US$ 7659 +99.0 CANDLR 1.3883 LME CASH ALUM US$ 1602.0 -4.0 CAN 30-YR 107.41 -0.15 BRENT CRUDE US$ 19.09 -0.27 --------------------MARKET COMMENT---------------------------- * Toronto stocks ended higher on Tuesday , buoyed by strength in golds and banking * Computer problems due to heavy trading in Bre - X Minerals hampered session * 84 million shares traded Toronto 's key stock index ended higher on Tuesday as the saga of Bre - X Minerals Ltd and its Indonesian gold find continued to dominate Canada 's biggest stock market . The TSE 300 Index climbed 50.15 points to close at 5900.37 in heavy turnover of 84.07 million shares worth C$ 1.4 billion . But the overall market was mixed with declining issues narrowly outpacing advances 476 to 464 . 298 issues were flat . Frantic trading in Bre - X collapsed the TSE 's computer trading system earlier in the day , forcing the exchange to halt trading in the stock before the market closed . Shares in the Calgary - based gold prospector were halted for a statement by the company this morning . When it resumed , a whopping 7.7 million shares changed hands in the first 22 minutes of trading before the system crashed . Bre - X closed up 1.35 at 3.85 . It was the first time Bre - X traded since investors lopped nearly C$ 3 billion off its stock market value last Thursday . TSE officials said the trading problems were due to old technology which will be replaced . On the Montreal Exchange , Bre - X closed up 0.81 at 3.50 on 9.8 million shares . Analysts predicted more volatility for Bre - X shares this week . \" The question of what Bre - X will release over the next few days will be important to the market , \" said Josef Schachter , of Schachter Asset Management Inc. The gold sector rose nearly 136 points , leading 12 of 14 sub - indices higher . Other strong groups included financial services , consumer products , energy and transportation . The TSE posted minor losses in forestry and real estate . --- HOT STOCKS --- * Among bank shares , Bank of Nova Scotia rose 0.65 to 51.50 on 2.1 million shares , while Canadian Imperial Bank of Commerce added 0.50 to 31.80 on 2.1 million shares . ( ( Reuters Toronto Bureau ( 416 ) 941 - 8100 ) )\n"
     ]
    }
   ],
   "source": [
    "path_to_preprocessed_train_docs = f\"train/preprocessed_docs_{version}.pkl\"\n",
    "\n",
    "try:\n",
    "    with open(path_to_preprocessed_train_docs, \"rb\") as f:\n",
    "        preprocessed_train_docs = pickle.load(f)\n",
    "except:\n",
    "    preprocessed_train_docs = preprocessing.preprocess_corpus(train_docs)\n",
    "    with open(path_to_preprocessed_train_docs, \"wb\") as f:\n",
    "        pickle.dump(preprocessed_train_docs, f)\n",
    "\n",
    "print(preprocessed_train_docs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_preprocessed_test_docs = f\"test/preprocessed_docs_{version}.pkl\"\n",
    "\n",
    "# try:\n",
    "#     with open(path_to_preprocessed_test_docs, \"rb\") as f:\n",
    "#         preprocessed_test_docs = pickle.load(f)\n",
    "# except:\n",
    "#     preprocessed_test_docs = preprocessing.preprocess_corpus(test_docs)\n",
    "#     with open(path_to_preprocessed_test_docs, \"wb\") as f:\n",
    "#         pickle.dump(preprocessed_test_docs, f)\n",
    "\n",
    "# print(preprocessed_test_docs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing the documents as token index sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = preprocessed_train_docs # add preprocessed_test_docs\n",
    "n_vocabulary = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721935\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=n_vocabulary, filters=\"\", lower=False)\n",
    "tokenizer.fit_on_texts(docs)\n",
    "word_idx = tokenizer.word_index\n",
    "if n_vocabulary is None:\n",
    "    n_vocabulary = len(word_idx) + 1 # use index 0 for padding\n",
    "\n",
    "print(n_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n",
      "(299773, 1280)\n",
      "[  2112    217    137    145     52   2639    593      2   3714   3714\n",
      "   9473 222813 376439   8514 222813   9051 376440  30534 170526 271220\n",
      "   4802     14   2981     13    587  22026 123436  55200 376441 376442\n",
      "   4802     14   3274      7   3355     13    587 222814  66463  15304\n",
      " 376443 191283   1660   5594  16940    587 376444 376445  24154 191284\n",
      "   1660   5594  23347    587 376446  14783   1709  11671 115825  34203\n",
      "  15729  13077    587  40699  46144  32689  36483     38   2112    217\n",
      "    226    145     12     85      3   5774     23   1043      6  11672\n",
      "      9    809     38   3318    700    167      4    901    181      6\n",
      "   3495      7   1927   6603   9271    593     38   4214     31     75]\n"
     ]
    }
   ],
   "source": [
    "n_sequence = 1280\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(docs)\n",
    "if n_sequence is None:\n",
    "    n_sequence = max([len(s) for s in sequences])\n",
    "sequence_lengths = [min(len(s), n_sequence) for s in sequences]\n",
    "sequences = pad_sequences(sequences,\n",
    "                          maxlen=n_sequence,\n",
    "                          padding=\"post\",\n",
    "                          truncating=\"post\")\n",
    "\n",
    "print(n_sequence)\n",
    "print(sequences.shape)\n",
    "print(sequences[2][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_lengths = [len(doc.split()) for doc in docs]\n",
    "\n",
    "sns.distplot(doc_lengths,\n",
    "             bins=np.arange(0, 2500, 25),\n",
    "             kde=False,\n",
    "             label=\"documents\")\n",
    "sns.distplot(sequence_lengths,\n",
    "             bins=np.arange(0, 2500, 25),\n",
    "             kde=False,\n",
    "             label=\"sequences\")\n",
    "total_word_coverage = np.round(np.sum(sequence_lengths) / np.sum(doc_lengths), 3)\n",
    "plt.title(f\"n_vocabulary={n_vocabulary}, n_sequence={n_sequence},\\n\"\n",
    "          f\"total_word_coverage={total_word_coverage}\")\n",
    "plt.xlim(0, 1550)\n",
    "plt.xlabel(\"length\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_embedding = 300 # 300 required by pretrained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721934\n",
      "['the', '.', ',', 'to', 'of', 'in', '-', 'a', 'and', '\"', 'said', 'on', ')', '(', \"'s\", 'for', 'The', 'at', 'was', '$', 'that', 'is', 'by', 'with', 'from', 'percent', 'it', 'be', '/', 'as', 'million', 'its', 'will', 'has', '--', 'were', 'not', '*', 'would', 'year', 'are', 'have', 'an', 'he', 'which', ':', 'had', 'market', 'up', 'A', 'but', 'after', 'N', 'this', 'company', 'one', 'been', 'U.S.', 'billion', 'also', 'government', 'last', 'or', '1997', 'two', 'their', 'they', 'first', 'over', 'new', '1', 'his', 'more', 'June', 'shares', 'about', 'week', 'It', 'than', 'share', 'Bank', 'who', 'I', '1996', 'Tuesday', '%', 'per', 'Wednesday', 'May', 'we', 'expected', 'July', 'Thursday', 'Monday', 'We', 'some', 'Friday', 'down', 'could', 'three']\n"
     ]
    }
   ],
   "source": [
    "reset_seed()\n",
    "\n",
    "# ft_path = f\"data/fasttext_{version}.model\"\n",
    "ft_path = f\"train/fasttext_{version}.model\"\n",
    "\n",
    "try:\n",
    "    ft = FastText.load(ft_path)\n",
    "except:\n",
    "    ft = FastText(sentences=[doc.split() for doc in docs], size=n_embedding,\n",
    "                  min_count=1, workers=cpu_count(), seed=seed)\n",
    "    ft.save(ft_path)\n",
    "\n",
    "print(len(list(ft.wv.vocab)))\n",
    "print(ft.wv.index2entity[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721934\n",
      "['the', '.', ',', 'to', 'of', 'in', '-', 'a', 'and', '\"', 'said', 'on', ')', '(', \"'s\", 'for', 'The', 'at', 'was', '$', 'that', 'is', 'by', 'with', 'from', 'percent', 'it', 'be', '/', 'as', 'million', 'its', 'will', 'has', '--', 'were', 'not', '*', 'would', 'year', 'are', 'have', 'an', 'he', 'which', ':', 'had', 'market', 'up', 'A', 'but', 'after', 'N', 'this', 'company', 'one', 'been', 'U.S.', 'billion', 'also', 'government', 'last', 'or', '1997', 'two', 'their', 'they', 'first', 'over', 'new', '1', 'his', 'more', 'June', 'shares', 'about', 'week', 'It', 'than', 'share', 'Bank', 'who', 'I', '1996', 'Tuesday', '%', 'per', 'Wednesday', 'May', 'we', 'expected', 'July', 'Thursday', 'Monday', 'We', 'some', 'Friday', 'down', 'could', 'three']\n"
     ]
    }
   ],
   "source": [
    "reset_seed()\n",
    "\n",
    "# w2v_path = f\"data/w2v_{version}.model\"\n",
    "w2v_path = f\"train/w2v_{version}.model\"\n",
    "\n",
    "try:\n",
    "    w2v = Word2Vec.load(w2v_path)\n",
    "except:\n",
    "    w2v = Word2Vec(sentences=[doc.split() for doc in docs], size=n_embedding,\n",
    "                   min_count=1, workers=cpu_count(), seed=seed)\n",
    "    w2v.save(w2v_path)\n",
    "\n",
    "print(len(list(w2v.wv.vocab)))\n",
    "print(w2v.wv.index2entity[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(fname, skip_first):\n",
    "    embedding_idx = {}\n",
    "    with open(fname, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i == 0 and skip_first:\n",
    "                continue\n",
    "            vals = line.rstrip().split()\n",
    "            token = \"\".join(vals[:-300])\n",
    "            embedding = np.array(vals[-300:], dtype=np.float32)\n",
    "            embedding_idx[token] = embedding\n",
    "    return embedding_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', 'the', '.', 'and', 'to', 'of', 'a', 'in', 'is', 'for', 'that', 'I', 'it', 'on', 'with', ')', ':', '\"', '(', 'The', 'you', 'was', 'are', 'or', 'this', 'as', 'have', 'at', 'from', '!', \"'s\", 'but', 'by', 'not', '?', 'your', 'all', '/', 'be', 'we', 'my', 'one', '-', 'will', 'they', 'so', 'which', '”', '“', 'has', '...', 'just', 'he', 'their', 'can', 'about', 'his', 'our', ';', 'when', 'more', 'had', 'do', 'some', 'time', 'like', 'also', 'there', 'them', 'get', 'what', 'out', \"'\", 'me', 'her', 'an', 'were', 'This', 'It', 'up', 'would', 'if', 'who', 'new', 'only', 'A', '–', 'people', 'any', 'We', 'make', 'other', 'In', 'then', 'its', 'use', 'said', 'now', 'no', 'first']\n"
     ]
    }
   ],
   "source": [
    "ft_pretrained = load_embeddings(\"data/crawl-300d-2M.vec\", skip_first=True)\n",
    "\n",
    "token_iter = iter(ft_pretrained)\n",
    "print([next(token_iter) for i in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', '.', 'the', 'and', 'to', 'of', 'a', 'in', '\"', ':', 'is', 'for', 'I', ')', '(', 'that', '-', 'on', 'you', 'with', \"'s\", 'it', 'The', 'are', 'by', 'at', 'be', 'this', 'as', 'from', 'was', 'have', 'or', '...', 'your', 'not', '!', '?', 'will', 'an', \"n't\", 'can', 'but', 'all', 'my', 'has', '|', 'do', 'we', 'they', 'more', 'one', 'about', 'he', ';', \"'\", 'out', '$', 'their', 'so', 'his', 'up', 'It', '&', 'like', '/', '1', 'which', 'if', 'would', 'our', '[', ']', 'me', 'who', 'just', 'This', 'time', 'what', 'A', '2', 'had', 'when', 'there', 'been', 'some', 'get', 'were', 'other', 'also', 'In', 'her', 'them', 'You', 'new', 'We', 'no', 'any', '>', 'people']\n"
     ]
    }
   ],
   "source": [
    "if version == \"tokenized_cased\":\n",
    "    glove_pretrained = load_embeddings(\"data/glove.840B.300d.txt\", skip_first=False)\n",
    "else:\n",
    "    glove_pretrained = load_embeddings(\"data/glove.42B.300d.txt\", skip_first=False)\n",
    "    \n",
    "token_iter = iter(glove_pretrained)\n",
    "print([next(token_iter) for i in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_embedding_matrix(embedding_model):\n",
    "    embedding_matrix = np.zeros((n_vocabulary, n_embedding))\n",
    "    unknown_token_count = 0\n",
    "    for token, i in word_idx.items():\n",
    "        if i >= n_vocabulary:\n",
    "            continue\n",
    "        if token in embedding_model:\n",
    "            embedding_matrix[i] = embedding_model[token]\n",
    "        else:\n",
    "            unknown_token_count += 1\n",
    "\n",
    "    print(unknown_token_count)\n",
    "    print(embedding_matrix.shape)\n",
    "    print(embedding_matrix[1][:20])\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(721935, 300)\n",
      "[-4.0380559   0.73253816  0.29080105 -0.94367075 -2.74553633 -1.0693239\n",
      "  4.74652195 -4.46533537  0.51952785  1.6970855  -2.17800879 -0.67886841\n",
      " -2.04955816 -1.98112869 -0.87719041 -2.77385116 -6.61758423 -2.44608641\n",
      "  3.39488935  3.47295785]\n"
     ]
    }
   ],
   "source": [
    "ft_embedding_matrix = create_embedding_matrix(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(721935, 300)\n",
      "[-1.22263086 -0.43641889 -2.61214328 -0.31139144  1.94224727 -1.06045961\n",
      " -2.03274608  0.41353998  0.17744918  1.05541265  0.79217201 -1.77697921\n",
      " -0.92401618  2.09578061 -1.47802079  0.23644187 -0.60706484  0.46562719\n",
      "  0.1738892   3.68998671]\n"
     ]
    }
   ],
   "source": [
    "w2v_embedding_matrix = create_embedding_matrix(w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466720\n",
      "(721935, 300)\n",
      "[ 0.0231      0.017       0.0157     -0.0773      0.1088      0.0031\n",
      " -0.1487     -0.26719999 -0.0357     -0.0487      0.0807      0.1532\n",
      " -0.0739     -0.0291     -0.0445     -0.0014      0.1014      0.0186\n",
      " -0.0253      0.02      ]\n"
     ]
    }
   ],
   "source": [
    "ft_pretrained_embedding_matrix = create_embedding_matrix(ft_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431107\n",
      "(721935, 300)\n",
      "[ 0.27204001 -0.06203    -0.1884      0.023225   -0.018158    0.0067192\n",
      " -0.13877     0.17708001  0.17709     2.58820009 -0.35179001 -0.17312001\n",
      "  0.43285    -0.10708     0.15006    -0.19982    -0.19092999  1.18710005\n",
      " -0.16207001 -0.23537999]\n"
     ]
    }
   ],
   "source": [
    "glove_pretrained_embedding_matrix = create_embedding_matrix(glove_pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = None\n",
    "x_train, y_train = shuffle(sequences[:n_train],\n",
    "                           train_labels,\n",
    "                           random_state=seed,\n",
    "                           n_samples=n_samples)\n",
    "# x_test = sequences[n_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-evaluating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_evaluate(model_initializer, batch_size=256, model_params={}):\n",
    "    model_initializer(n_vocabulary, n_embedding, n_sequence, n_labels,\n",
    "                      **model_params).summary()\n",
    "\n",
    "    cv_scores = []\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=5, random_state=seed)\n",
    "    for train, val in mskf.split(x_train, y_train):\n",
    "        model = model_initializer(n_vocabulary, n_embedding, n_sequence, n_labels,\n",
    "                                  **model_params)\n",
    "        es = EarlyStopping(patience=10, verbose=1, restore_best_weights=True)\n",
    "        history = model.fit(x_train[train],\n",
    "                            y_train[train],\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=100,\n",
    "                            verbose=1,\n",
    "                            validation_data=(x_train[val], y_train[val]),\n",
    "                            callbacks=[es])\n",
    "\n",
    "        y_val_pred_prob = model.predict(x_train[val], batch_size=batch_size, verbose=1)\n",
    "        y_val_pred = np.round(y_val_pred_prob)\n",
    "\n",
    "        scores = {}\n",
    "        scores[\"accuracy\"] = accuracy_score(y_train[val], y_val_pred)\n",
    "        scores[\"F1 (macro)\"] = f1_score(y_train[val], y_val_pred, average=\"macro\")\n",
    "        scores[\"F1 (micro)\"] = f1_score(y_train[val], y_val_pred, average=\"micro\")\n",
    "        scores[\"LRAP\"] = label_ranking_average_precision_score(y_train[val],\n",
    "                                                               y_val_pred_prob)\n",
    "        scores[\"NDCG\"] = ndcg_score(y_train[val], y_val_pred_prob)\n",
    "        scores[\"timestamp\"] = round(datetime.timestamp(datetime.now()))\n",
    "        cv_scores.append(scores)\n",
    "        print(scores)\n",
    "        \n",
    "        np.savetxt(f\"val_results/{model_initializer.__name__}_{version}_\" +\n",
    "                   f\"{scores['timestamp']}_\" +\n",
    "                   f\"{np.round(scores['F1 (micro)'], 6)}.txt\", y_val_pred, fmt=\"%d\")\n",
    "\n",
    "    cv_scores_df = pd.DataFrame(cv_scores)\n",
    "    display(cv_scores_df)\n",
    "    print(cv_scores_df.drop(\"timestamp\", axis=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_25 (Embedding)     (None, 1280, 300)         216580500 \n",
      "_________________________________________________________________\n",
      "bidirectional_28 (Bidirectio (None, 512)               1140736   \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 126)               64638     \n",
      "=================================================================\n",
      "Total params: 217,785,874\n",
      "Trainable params: 1,205,374\n",
      "Non-trainable params: 216,580,500\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 160s 170ms/step - loss: 0.0135 - val_loss: 0.0076\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 147s 157ms/step - loss: 0.0067 - val_loss: 0.0059\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 147s 157ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 147s 157ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 147s 157ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 147s 157ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 154s 164ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 148s 157ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 147s 157ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 147s 157ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 147s 157ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 147s 157ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 147s 157ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 147s 157ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 146s 156ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 149s 159ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 146s 156ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 146s 156ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 146s 156ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 146s 155ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 146s 156ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 146s 156ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 145s 155ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - 146s 156ms/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 25/100\n",
      "937/937 [==============================] - 146s 156ms/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 26/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0029Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 149s 159ms/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 00026: early stopping\n",
      "235/235 [==============================] - 14s 58ms/step\n",
      "{'accuracy': 0.692642570013177, 'F1 (macro)': 0.5945094264683496, 'F1 (micro)': 0.8916142039092402, 'LRAP': 0.9557532457619212, 'NDCG': 0.9740508521520123, 'timestamp': 1590742566}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 156s 166ms/step - loss: 0.0131 - val_loss: 0.0077\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 147s 156ms/step - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 147s 157ms/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 147s 157ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 147s 157ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 6/100\n",
      "501/937 [===============>..............] - ETA: 1:01 - loss: 0.0046"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-434cae77c34b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m cross_evaluate(models.bi_lstm_1, model_params={\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"filters_1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"filters_2\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"mean_squared_error\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \"embedding_matrix\": ft_pretrained_embedding_matrix})\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-afe9f0c7c33f>\u001b[0m in \u001b[0;36mcross_evaluate\u001b[0;34m(model_initializer, batch_size, model_params)\u001b[0m\n\u001b[1;32m     15\u001b[0m                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                             callbacks=[es])\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0my_val_pred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.bi_lstm_1, model_params={\n",
    "    \"filters_1\": 400, \"filters_2\": 500, \"loss\": \"mean_squared_error\",\n",
    "    \"embedding_matrix\": ft_pretrained_embedding_matrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 1280, 300)         216580500 \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 1279, 400)         240400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 1279, 400)         1600      \n",
      "_________________________________________________________________\n",
      "re_lu_32 (ReLU)              (None, 1279, 400)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 639, 400)          0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 639, 400)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 638, 500)          400500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 638, 500)          2000      \n",
      "_________________________________________________________________\n",
      "re_lu_33 (ReLU)              (None, 638, 500)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 319, 500)          0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 319, 500)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_16 (Bidirectio (None, 512)               1550336   \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 126)               64638     \n",
      "=================================================================\n",
      "Total params: 218,839,974\n",
      "Trainable params: 2,257,674\n",
      "Non-trainable params: 216,582,300\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 105s 112ms/step - loss: 0.0126 - val_loss: 0.0069\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0060 - val_loss: 0.0054\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 104s 111ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 103s 110ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 104s 111ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 25/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 26/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 27/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 28/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 29/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 30/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 31/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 32/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0027Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 104s 111ms/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 00032: early stopping\n",
      "235/235 [==============================] - 8s 35ms/step\n",
      "{'accuracy': 0.7004653645355529, 'F1 (macro)': 0.60755797946432, 'F1 (micro)': 0.8951616094725763, 'LRAP': 0.9579113188973041, 'NDCG': 0.9750741082302394, 'timestamp': 1590644566}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 108s 115ms/step - loss: 0.0120 - val_loss: 0.0067\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 25/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0029Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 104s 111ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 00025: early stopping\n",
      "235/235 [==============================] - 8s 35ms/step\n",
      "{'accuracy': 0.6980634830617317, 'F1 (macro)': 0.5850389157838546, 'F1 (micro)': 0.8936557067180673, 'LRAP': 0.9571290601930558, 'NDCG': 0.9738247624041733, 'timestamp': 1590647158}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 105s 112ms/step - loss: 0.0123 - val_loss: 0.0067\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 25/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 26/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 27/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 28/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 29/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0028Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 104s 111ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 00029: early stopping\n",
      "235/235 [==============================] - 8s 35ms/step\n",
      "{'accuracy': 0.7002718433648538, 'F1 (macro)': 0.5980024899161356, 'F1 (micro)': 0.8962183438268972, 'LRAP': 0.9576070283904078, 'NDCG': 0.9775072249534544, 'timestamp': 1590650152}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 106s 113ms/step - loss: 0.0124 - val_loss: 0.0070\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 103s 109ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0029Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 104s 110ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 00024: early stopping\n",
      "235/235 [==============================] - 8s 35ms/step\n",
      "{'accuracy': 0.6976798492152186, 'F1 (macro)': 0.593151882114134, 'F1 (micro)': 0.8938086244132577, 'LRAP': 0.9576194096946063, 'NDCG': 0.9747067966595505, 'timestamp': 1590652647}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 105s 113ms/step - loss: 0.0120 - val_loss: 0.0067\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0030Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 104s 111ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 00022: early stopping\n",
      "235/235 [==============================] - 8s 35ms/step\n",
      "{'accuracy': 0.6988140710223008, 'F1 (macro)': 0.5763341486992942, 'F1 (micro)': 0.8932248975751227, 'LRAP': 0.9563406354958381, 'NDCG': 0.975055288320791, 'timestamp': 1590654934}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1 (macro)</th>\n",
       "      <th>F1 (micro)</th>\n",
       "      <th>LRAP</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.700465</td>\n",
       "      <td>0.607558</td>\n",
       "      <td>0.895162</td>\n",
       "      <td>0.957911</td>\n",
       "      <td>0.975074</td>\n",
       "      <td>1590644566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.698063</td>\n",
       "      <td>0.585039</td>\n",
       "      <td>0.893656</td>\n",
       "      <td>0.957129</td>\n",
       "      <td>0.973825</td>\n",
       "      <td>1590647158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.700272</td>\n",
       "      <td>0.598002</td>\n",
       "      <td>0.896218</td>\n",
       "      <td>0.957607</td>\n",
       "      <td>0.977507</td>\n",
       "      <td>1590650152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.697680</td>\n",
       "      <td>0.593152</td>\n",
       "      <td>0.893809</td>\n",
       "      <td>0.957619</td>\n",
       "      <td>0.974707</td>\n",
       "      <td>1590652647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.698814</td>\n",
       "      <td>0.576334</td>\n",
       "      <td>0.893225</td>\n",
       "      <td>0.956341</td>\n",
       "      <td>0.975055</td>\n",
       "      <td>1590654934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  F1 (macro)  F1 (micro)      LRAP      NDCG   timestamp\n",
       "0  0.700465    0.607558    0.895162  0.957911  0.975074  1590644566\n",
       "1  0.698063    0.585039    0.893656  0.957129  0.973825  1590647158\n",
       "2  0.700272    0.598002    0.896218  0.957607  0.977507  1590650152\n",
       "3  0.697680    0.593152    0.893809  0.957619  0.974707  1590652647\n",
       "4  0.698814    0.576334    0.893225  0.956341  0.975055  1590654934"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy      0.699059\n",
      "F1 (macro)    0.592017\n",
      "F1 (micro)    0.894414\n",
      "LRAP          0.957321\n",
      "NDCG          0.975234\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.cnn_bi_lstm_1, model_params={\n",
    "    \"filters_1\": 400, \"filters_2\": 500, \"loss\": \"mean_squared_error\",\n",
    "    \"embedding_matrix\": ft_pretrained_embedding_matrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 1280, 300)         216580500 \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 1279, 400)         240400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 1279, 400)         1600      \n",
      "_________________________________________________________________\n",
      "re_lu_32 (ReLU)              (None, 1279, 400)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 639, 400)          0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 639, 400)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 638, 500)          400500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 638, 500)          2000      \n",
      "_________________________________________________________________\n",
      "re_lu_33 (ReLU)              (None, 638, 500)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 319, 500)          0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 319, 500)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_10 (Bidirectio (None, 319, 512)          1550336   \n",
      "_________________________________________________________________\n",
      "bidirectional_11 (Bidirectio (None, 256)               656384    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 126)               32382     \n",
      "=================================================================\n",
      "Total params: 219,464,102\n",
      "Trainable params: 2,881,802\n",
      "Non-trainable params: 216,582,300\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 194s 207ms/step - loss: 0.0155 - val_loss: 0.0092\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 188s 201ms/step - loss: 0.0074 - val_loss: 0.0062\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 188s 200ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 188s 200ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 188s 201ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 188s 200ms/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 188s 200ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 25/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 26/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 27/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0029Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 189s 202ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 00027: early stopping\n",
      "235/235 [==============================] - 14s 61ms/step\n",
      "{'accuracy': 0.7004153253381816, 'F1 (macro)': 0.5859938515675387, 'F1 (micro)': 0.8942945693502178, 'LRAP': 0.9574613970164665, 'NDCG': 0.9748480307382144, 'timestamp': 1590709063}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 192s 205ms/step - loss: 0.0151 - val_loss: 0.0090\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0072 - val_loss: 0.0061\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 189s 201ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 188s 200ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0032 - val_loss: 0.0042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - 185s 198ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 25/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 26/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 27/100\n",
      "937/937 [==============================] - 190s 203ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 28/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 29/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0028Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 189s 201ms/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 00029: early stopping\n",
      "235/235 [==============================] - 14s 61ms/step\n",
      "{'accuracy': 0.7006154821276667, 'F1 (macro)': 0.5864979565178109, 'F1 (micro)': 0.8940286581793001, 'LRAP': 0.9576806964389426, 'NDCG': 0.9742428948806676, 'timestamp': 1590714557}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 193s 206ms/step - loss: 0.0160 - val_loss: 0.0097\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0075 - val_loss: 0.0060\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 188s 200ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 188s 200ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 185s 198ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 25/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 26/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 27/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 28/100\n",
      "937/937 [==============================] - 189s 202ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 29/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 30/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0028Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 189s 202ms/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 00030: early stopping\n",
      "235/235 [==============================] - 14s 61ms/step\n",
      "{'accuracy': 0.7081269491836361, 'F1 (macro)': 0.5908823990227341, 'F1 (micro)': 0.8961091910069844, 'LRAP': 0.9574568614613005, 'NDCG': 0.9773950895853114, 'timestamp': 1590720249}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 193s 206ms/step - loss: 0.0155 - val_loss: 0.0090\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0074 - val_loss: 0.0062\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 185s 198ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 185s 198ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 185s 198ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - 190s 203ms/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 25/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937/937 [==============================] - 185s 198ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 27/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 28/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 29/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 30/100\n",
      "937/937 [==============================] - 185s 197ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 31/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0028Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 189s 202ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 00031: early stopping\n",
      "235/235 [==============================] - 14s 61ms/step\n",
      "{'accuracy': 0.701766383667206, 'F1 (macro)': 0.5844432029881708, 'F1 (micro)': 0.8939940890578405, 'LRAP': 0.9569995696068098, 'NDCG': 0.9743710794190653, 'timestamp': 1590726114}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 194s 207ms/step - loss: 0.0163 - val_loss: 0.0098\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 188s 200ms/step - loss: 0.0077 - val_loss: 0.0064\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 188s 201ms/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 188s 200ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 188s 201ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 188s 200ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 188s 201ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 188s 201ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 188s 200ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 188s 201ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 188s 201ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 188s 201ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 188s 201ms/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 188s 200ms/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 25/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 26/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 27/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 28/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0028Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 189s 202ms/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 00028: early stopping\n",
      "235/235 [==============================] - 14s 61ms/step\n",
      "{'accuracy': 0.7024836121628609, 'F1 (macro)': 0.5823873079593338, 'F1 (micro)': 0.8945702692145187, 'LRAP': 0.9571115394174263, 'NDCG': 0.975610595972027, 'timestamp': 1590731445}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1 (macro)</th>\n",
       "      <th>F1 (micro)</th>\n",
       "      <th>LRAP</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.700415</td>\n",
       "      <td>0.585994</td>\n",
       "      <td>0.894295</td>\n",
       "      <td>0.957461</td>\n",
       "      <td>0.974848</td>\n",
       "      <td>1590709063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.700615</td>\n",
       "      <td>0.586498</td>\n",
       "      <td>0.894029</td>\n",
       "      <td>0.957681</td>\n",
       "      <td>0.974243</td>\n",
       "      <td>1590714557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.708127</td>\n",
       "      <td>0.590882</td>\n",
       "      <td>0.896109</td>\n",
       "      <td>0.957457</td>\n",
       "      <td>0.977395</td>\n",
       "      <td>1590720249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.701766</td>\n",
       "      <td>0.584443</td>\n",
       "      <td>0.893994</td>\n",
       "      <td>0.957000</td>\n",
       "      <td>0.974371</td>\n",
       "      <td>1590726114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.702484</td>\n",
       "      <td>0.582387</td>\n",
       "      <td>0.894570</td>\n",
       "      <td>0.957112</td>\n",
       "      <td>0.975611</td>\n",
       "      <td>1590731445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  F1 (macro)  F1 (micro)      LRAP      NDCG   timestamp\n",
       "0  0.700415    0.585994    0.894295  0.957461  0.974848  1590709063\n",
       "1  0.700615    0.586498    0.894029  0.957681  0.974243  1590714557\n",
       "2  0.708127    0.590882    0.896109  0.957457  0.977395  1590720249\n",
       "3  0.701766    0.584443    0.893994  0.957000  0.974371  1590726114\n",
       "4  0.702484    0.582387    0.894570  0.957112  0.975611  1590731445"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy      0.702682\n",
      "F1 (macro)    0.586041\n",
      "F1 (micro)    0.894599\n",
      "LRAP          0.957342\n",
      "NDCG          0.975294\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.cnn_bi_lstm_2, model_params={\n",
    "    \"filters_1\": 400, \"filters_2\": 500, \"loss\": \"mean_squared_error\",\n",
    "    \"embedding_matrix\": ft_pretrained_embedding_matrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.bi_lstm_1, model_params={\n",
    "    \"filters_1\": 400, \"filters_2\": 500, \"loss\": \"mean_squared_error\",\n",
    "    \"embedding_matrix\": glove_pretrained_embedding_matrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 1280, 300)         216580500 \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 1279, 400)         240400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 1279, 400)         1600      \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               (None, 1279, 400)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 639, 400)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 639, 400)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 638, 500)          400500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 638, 500)          2000      \n",
      "_________________________________________________________________\n",
      "re_lu_9 (ReLU)               (None, 638, 500)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 319, 500)          0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 319, 500)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 512)               1550336   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 126)               64638     \n",
      "=================================================================\n",
      "Total params: 218,839,974\n",
      "Trainable params: 2,257,674\n",
      "Non-trainable params: 216,582,300\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1\n",
      "937/937 [==============================] - 105s 113ms/step - loss: 0.0123 - val_loss: 0.0069\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 25/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 26/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 27/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 28/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 29/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 30/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 31/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 32/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 33/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 34/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 35/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 36/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0028Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 104s 111ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 00036: early stopping\n",
      "235/235 [==============================] - 8s 35ms/step\n",
      "{'accuracy': 0.6996146981802411, 'F1 (macro)': 0.6099986527167284, 'F1 (micro)': 0.8944168810080713, 'LRAP': 0.957845382008498, 'NDCG': 0.9750636255295023, 'timestamp': 1590614239}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1\n",
      "937/937 [==============================] - 105s 113ms/step - loss: 0.0122 - val_loss: 0.0071\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0062 - val_loss: 0.0055\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 103s 110ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0040 - val_loss: 0.0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 25/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 26/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 27/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0030Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 104s 111ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 00027: early stopping\n",
      "235/235 [==============================] - 8s 35ms/step\n",
      "{'accuracy': 0.6947442163027705, 'F1 (macro)': 0.5855561692435826, 'F1 (micro)': 0.8934894633428134, 'LRAP': 0.9571018526191212, 'NDCG': 0.9738565697371458, 'timestamp': 1590617038}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1\n",
      "937/937 [==============================] - 104s 111ms/step - loss: 0.0120 - val_loss: 0.0067\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - 104s 111ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 25/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 26/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 27/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0030Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 103s 110ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 00027: early stopping\n",
      "235/235 [==============================] - 8s 35ms/step\n",
      "{'accuracy': 0.70095562115375, 'F1 (macro)': 0.592694063262955, 'F1 (micro)': 0.8953119492421572, 'LRAP': 0.9573985290166792, 'NDCG': 0.9775055741235298, 'timestamp': 1590619835}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1\n",
      "937/937 [==============================] - 105s 112ms/step - loss: 0.0125 - val_loss: 0.0072\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0030Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 104s 111ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 00024: early stopping\n",
      "235/235 [==============================] - 8s 35ms/step\n",
      "{'accuracy': 0.6952279285440262, 'F1 (macro)': 0.5858498557319883, 'F1 (micro)': 0.893548395639083, 'LRAP': 0.9575089493998343, 'NDCG': 0.9746993873957732, 'timestamp': 1590622324}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 106s 113ms/step - loss: 0.0120 - val_loss: 0.0068\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 103s 110ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 25/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 26/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 27/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 28/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 29/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 30/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 31/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0029Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 104s 111ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 00031: early stopping\n",
      "235/235 [==============================] - 8s 35ms/step\n",
      "{'accuracy': 0.6987973912898438, 'F1 (macro)': 0.600216194326502, 'F1 (micro)': 0.8938988185718704, 'LRAP': 0.9571701950637933, 'NDCG': 0.9753858251654524, 'timestamp': 1590625533}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1 (macro)</th>\n",
       "      <th>F1 (micro)</th>\n",
       "      <th>LRAP</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.699615</td>\n",
       "      <td>0.609999</td>\n",
       "      <td>0.894417</td>\n",
       "      <td>0.957845</td>\n",
       "      <td>0.975064</td>\n",
       "      <td>1590614239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.694744</td>\n",
       "      <td>0.585556</td>\n",
       "      <td>0.893489</td>\n",
       "      <td>0.957102</td>\n",
       "      <td>0.973857</td>\n",
       "      <td>1590617038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.700956</td>\n",
       "      <td>0.592694</td>\n",
       "      <td>0.895312</td>\n",
       "      <td>0.957399</td>\n",
       "      <td>0.977506</td>\n",
       "      <td>1590619835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.695228</td>\n",
       "      <td>0.585850</td>\n",
       "      <td>0.893548</td>\n",
       "      <td>0.957509</td>\n",
       "      <td>0.974699</td>\n",
       "      <td>1590622324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.698797</td>\n",
       "      <td>0.600216</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.957170</td>\n",
       "      <td>0.975386</td>\n",
       "      <td>1590625533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  F1 (macro)  F1 (micro)      LRAP      NDCG   timestamp\n",
       "0  0.699615    0.609999    0.894417  0.957845  0.975064  1590614239\n",
       "1  0.694744    0.585556    0.893489  0.957102  0.973857  1590617038\n",
       "2  0.700956    0.592694    0.895312  0.957399  0.977506  1590619835\n",
       "3  0.695228    0.585850    0.893548  0.957509  0.974699  1590622324\n",
       "4  0.698797    0.600216    0.893899  0.957170  0.975386  1590625533"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy      0.697868\n",
      "F1 (macro)    0.594863\n",
      "F1 (micro)    0.894133\n",
      "LRAP          0.957405\n",
      "NDCG          0.975302\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.cnn_bi_lstm_1, model_params={\n",
    "    \"filters_1\": 400, \"filters_2\": 500, \"loss\": \"mean_squared_error\",\n",
    "    \"embedding_matrix\": glove_pretrained_embedding_matrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (None, 1280, 300)         216580500 \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 1279, 400)         240400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 1279, 400)         1600      \n",
      "_________________________________________________________________\n",
      "re_lu_44 (ReLU)              (None, 1279, 400)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 639, 400)          0         \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 639, 400)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 638, 500)          400500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 638, 500)          2000      \n",
      "_________________________________________________________________\n",
      "re_lu_45 (ReLU)              (None, 638, 500)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 319, 500)          0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 319, 500)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_22 (Bidirectio (None, 319, 512)          1550336   \n",
      "_________________________________________________________________\n",
      "bidirectional_23 (Bidirectio (None, 256)               656384    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 126)               32382     \n",
      "=================================================================\n",
      "Total params: 219,464,102\n",
      "Trainable params: 2,881,802\n",
      "Non-trainable params: 216,582,300\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 194s 207ms/step - loss: 0.0154 - val_loss: 0.0094\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 188s 201ms/step - loss: 0.0077 - val_loss: 0.0064\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 188s 200ms/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 188s 200ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 188s 201ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 188s 201ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 188s 200ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 193s 206ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 188s 200ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 189s 201ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 188s 201ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 188s 201ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 25/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 26/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 27/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 28/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 29/100\n",
      "937/937 [==============================] - 185s 198ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 30/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0029Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 189s 202ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 00030: early stopping\n",
      "235/235 [==============================] - 14s 61ms/step\n",
      "{'accuracy': 0.7036511934348573, 'F1 (macro)': 0.5802500331205263, 'F1 (micro)': 0.89503058611218, 'LRAP': 0.9576012224664152, 'NDCG': 0.9748892929712651, 'timestamp': 1590737170}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 192s 205ms/step - loss: 0.0154 - val_loss: 0.0092\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 188s 200ms/step - loss: 0.0075 - val_loss: 0.0062\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 188s 201ms/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 188s 200ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 188s 201ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 8/100\n",
      "547/937 [================>.............] - ETA: 1:11 - loss: 0.0042"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f71ae84d8883>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m cross_evaluate(models.cnn_bi_lstm_2, model_params={\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"filters_1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"filters_2\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"mean_squared_error\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \"embedding_matrix\": glove_pretrained_embedding_matrix})\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-afe9f0c7c33f>\u001b[0m in \u001b[0;36mcross_evaluate\u001b[0;34m(model_initializer, batch_size, model_params)\u001b[0m\n\u001b[1;32m     15\u001b[0m                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                             callbacks=[es])\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0my_val_pred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/projappl/project_2002961/DL-2020-Shakespeare/venv/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.cnn_bi_lstm_2, model_params={\n",
    "    \"filters_1\": 400, \"filters_2\": 500, \"loss\": \"mean_squared_error\",\n",
    "    \"embedding_matrix\": glove_pretrained_embedding_matrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 1280, 300)         216580500 \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 1279, 400)         240400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 1279, 400)         1600      \n",
      "_________________________________________________________________\n",
      "re_lu_20 (ReLU)              (None, 1279, 400)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 639, 400)          0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 639, 400)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 638, 500)          400500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 638, 500)          2000      \n",
      "_________________________________________________________________\n",
      "re_lu_21 (ReLU)              (None, 638, 500)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 319, 500)          0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 319, 500)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_10 (Bidirectio (None, 512)               1550336   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 126)               64638     \n",
      "=================================================================\n",
      "Total params: 218,839,974\n",
      "Trainable params: 2,257,674\n",
      "Non-trainable params: 216,582,300\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 105s 112ms/step - loss: 0.0118 - val_loss: 0.0068\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 25/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 26/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 27/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 28/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 29/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 30/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 31/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 32/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 33/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 34/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 35/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 36/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0029Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 104s 111ms/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 00036: early stopping\n",
      "235/235 [==============================] - 8s 35ms/step\n",
      "{'accuracy': 0.6976131302853902, 'F1 (macro)': 0.5967597006041393, 'F1 (micro)': 0.8934129578897726, 'LRAP': 0.9565761366474064, 'NDCG': 0.9742580700160459, 'timestamp': 1590629244}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 106s 113ms/step - loss: 0.0115 - val_loss: 0.0069\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 103s 110ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 103s 110ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 25/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 26/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 27/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 28/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0031Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 103s 110ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 00028: early stopping\n",
      "235/235 [==============================] - 8s 35ms/step\n",
      "{'accuracy': 0.6945774189781996, 'F1 (macro)': 0.586611523901755, 'F1 (micro)': 0.8920884793413109, 'LRAP': 0.9564271165656169, 'NDCG': 0.9735160716927607, 'timestamp': 1590632147}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 108s 116ms/step - loss: 0.0118 - val_loss: 0.0067\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0062 - val_loss: 0.0055\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 25/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 26/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 27/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 28/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 29/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0031Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 103s 110ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 00029: early stopping\n",
      "235/235 [==============================] - 8s 35ms/step\n",
      "{'accuracy': 0.6978536048431481, 'F1 (macro)': 0.5818719035826683, 'F1 (micro)': 0.8944098063354645, 'LRAP': 0.9557885633498825, 'NDCG': 0.9765387630283455, 'timestamp': 1590635140}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 106s 113ms/step - loss: 0.0118 - val_loss: 0.0069\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 25/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 26/100\n",
      "937/937 [==============================] - 100s 107ms/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 27/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0032Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 103s 110ms/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 00027: early stopping\n",
      "235/235 [==============================] - 8s 35ms/step\n",
      "{'accuracy': 0.6934598769035745, 'F1 (macro)': 0.5766896282297278, 'F1 (micro)': 0.8925363708969145, 'LRAP': 0.9564551508429783, 'NDCG': 0.974152786571854, 'timestamp': 1590637937}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "937/937 [==============================] - 106s 113ms/step - loss: 0.0114 - val_loss: 0.0067\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 102s 109ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 25/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 26/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 27/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 28/100\n",
      "937/937 [==============================] - 101s 108ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 29/100\n",
      "937/937 [==============================] - 102s 108ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 30/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 31/100\n",
      "937/937 [==============================] - 101s 107ms/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 32/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0030Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 104s 111ms/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 00032: early stopping\n",
      "235/235 [==============================] - 8s 35ms/step\n",
      "{'accuracy': 0.6972628559037913, 'F1 (macro)': 0.5863334061351266, 'F1 (micro)': 0.8933846988892861, 'LRAP': 0.9565013816780705, 'NDCG': 0.9752165230207485, 'timestamp': 1590641238}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1 (macro)</th>\n",
       "      <th>F1 (micro)</th>\n",
       "      <th>LRAP</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.697613</td>\n",
       "      <td>0.596760</td>\n",
       "      <td>0.893413</td>\n",
       "      <td>0.956576</td>\n",
       "      <td>0.974258</td>\n",
       "      <td>1590629244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.694577</td>\n",
       "      <td>0.586612</td>\n",
       "      <td>0.892088</td>\n",
       "      <td>0.956427</td>\n",
       "      <td>0.973516</td>\n",
       "      <td>1590632147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.697854</td>\n",
       "      <td>0.581872</td>\n",
       "      <td>0.894410</td>\n",
       "      <td>0.955789</td>\n",
       "      <td>0.976539</td>\n",
       "      <td>1590635140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.693460</td>\n",
       "      <td>0.576690</td>\n",
       "      <td>0.892536</td>\n",
       "      <td>0.956455</td>\n",
       "      <td>0.974153</td>\n",
       "      <td>1590637937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.697263</td>\n",
       "      <td>0.586333</td>\n",
       "      <td>0.893385</td>\n",
       "      <td>0.956501</td>\n",
       "      <td>0.975217</td>\n",
       "      <td>1590641238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  F1 (macro)  F1 (micro)      LRAP      NDCG   timestamp\n",
       "0  0.697613    0.596760    0.893413  0.956576  0.974258  1590629244\n",
       "1  0.694577    0.586612    0.892088  0.956427  0.973516  1590632147\n",
       "2  0.697854    0.581872    0.894410  0.955789  0.976539  1590635140\n",
       "3  0.693460    0.576690    0.892536  0.956455  0.974153  1590637937\n",
       "4  0.697263    0.586333    0.893385  0.956501  0.975217  1590641238"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy      0.696153\n",
      "F1 (macro)    0.585653\n",
      "F1 (micro)    0.893166\n",
      "LRAP          0.956350\n",
      "NDCG          0.974736\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.cnn_bi_lstm_1, model_params={\n",
    "    \"filters_1\": 400, \"filters_2\": 500, \"loss\": \"mean_squared_error\",\n",
    "    \"embedding_matrix\": w2v_embedding_matrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1280)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1280, 300)    216580500   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1280, 300)    216580500   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 1279, 400)    240400      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1279, 400)    240400      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1279, 400)    1600        conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1279, 400)    1600        conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 1279, 400)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 1279, 400)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 639, 400)     0           re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 639, 400)     0           re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 639, 400)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 639, 400)     0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 638, 500)     400500      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 638, 500)     400500      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 638, 500)     2000        conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 638, 500)     2000        conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 638, 500)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 638, 500)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 319, 500)     0           re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 319, 500)     0           re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 319, 500)     0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 319, 500)     0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 319, 1000)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 512)          2574336     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 126)          64638       bidirectional[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 437,088,974\n",
      "Trainable params: 3,924,374\n",
      "Non-trainable params: 433,164,600\n",
      "__________________________________________________________________________________________________\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 24 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 24 all-reduces with algorithm = nccl, num_packs = 1\n",
      "937/937 [==============================] - 189s 202ms/step - loss: 0.0132 - val_loss: 0.0076\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 184s 196ms/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937/937 [==============================] - 184s 196ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 184s 196ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 182s 194ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 182s 194ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 183s 195ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 180s 192ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 181s 193ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 182s 194ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 179s 191ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 181s 194ms/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 182s 194ms/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 183s 195ms/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0028Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 189s 201ms/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 00019: early stopping\n",
      "235/235 [==============================] - 12s 51ms/step\n",
      "{'accuracy': 0.691741864460494, 'F1 (macro)': 0.5670392959466158, 'F1 (micro)': 0.8928576160958713, 'LRAP': 0.9561248837670545, 'NDCG': 0.9743007550117433, 'timestamp': 1590686628}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 24 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 24 all-reduces with algorithm = nccl, num_packs = 1\n",
      "937/937 [==============================] - 190s 203ms/step - loss: 0.0131 - val_loss: 0.0080\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 189s 202ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 188s 200ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 188s 200ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 185s 197ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 183s 195ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 190s 203ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 182s 194ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 187s 200ms/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 183s 195ms/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 182s 194ms/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0027Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 194s 207ms/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 00022: early stopping\n",
      "235/235 [==============================] - 12s 51ms/step\n",
      "{'accuracy': 0.6923423348289494, 'F1 (macro)': 0.5913536455005562, 'F1 (micro)': 0.8934541238014051, 'LRAP': 0.956524782303733, 'NDCG': 0.973464345800029, 'timestamp': 1590690795}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 24 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 24 all-reduces with algorithm = nccl, num_packs = 1\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0136 - val_loss: 0.0079\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 179s 191ms/step - loss: 0.0065 - val_loss: 0.0055\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 177s 189ms/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 176s 188ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 176s 188ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 179s 191ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 176s 188ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 177s 189ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 176s 188ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 177s 189ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 170s 182ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 177s 189ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 176s 188ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 179s 191ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 174s 186ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 174s 186ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 176s 187ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 177s 189ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 176s 187ms/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 177s 189ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 174s 186ms/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 176s 187ms/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 173s 185ms/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0026Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 181s 194ms/step - loss: 0.0026 - val_loss: 0.0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00024: early stopping\n",
      "235/235 [==============================] - 12s 51ms/step\n",
      "{'accuracy': 0.6996881306182352, 'F1 (macro)': 0.5940477897093919, 'F1 (micro)': 0.8943023477762931, 'LRAP': 0.9569789016105978, 'NDCG': 0.9771867429758417, 'timestamp': 1590695100}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 24 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 24 all-reduces with algorithm = nccl, num_packs = 1\n",
      "937/937 [==============================] - 192s 205ms/step - loss: 0.0128 - val_loss: 0.0073\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 189s 201ms/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 189s 202ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 192s 205ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 190s 203ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 188s 200ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 190s 203ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 185s 198ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 190s 203ms/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 186s 199ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 185s 197ms/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 185s 198ms/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 185s 197ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 186s 198ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 183s 195ms/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0027Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 193s 206ms/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 00022: early stopping\n",
      "235/235 [==============================] - 12s 51ms/step\n",
      "{'accuracy': 0.69302620385969, 'F1 (macro)': 0.5825851272538847, 'F1 (micro)': 0.8923128507675974, 'LRAP': 0.955482013230834, 'NDCG': 0.9733278111839783, 'timestamp': 1590699287}\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 24 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 24 all-reduces with algorithm = nccl, num_packs = 1\n",
      "937/937 [==============================] - 192s 205ms/step - loss: 0.0129 - val_loss: 0.0076\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 194s 208ms/step - loss: 0.0065 - val_loss: 0.0056\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 193s 206ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 197s 210ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 194s 207ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 194s 207ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 195s 208ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 191s 204ms/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 193s 206ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 191s 204ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 194s 207ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 195s 208ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 190s 202ms/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 194s 207ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 190s 203ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 192s 205ms/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 191s 204ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 191s 204ms/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 192s 204ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 188s 201ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 195s 208ms/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.0027Restoring model weights from the end of the best epoch.\n",
      "937/937 [==============================] - 198s 212ms/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 00022: early stopping\n",
      "235/235 [==============================] - 12s 51ms/step\n",
      "{'accuracy': 0.6955782029256251, 'F1 (macro)': 0.5790312724327306, 'F1 (micro)': 0.8929411074800485, 'LRAP': 0.956230828652963, 'NDCG': 0.9748486436988807, 'timestamp': 1590703613}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1 (macro)</th>\n",
       "      <th>F1 (micro)</th>\n",
       "      <th>LRAP</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.691742</td>\n",
       "      <td>0.567039</td>\n",
       "      <td>0.892858</td>\n",
       "      <td>0.956125</td>\n",
       "      <td>0.974301</td>\n",
       "      <td>1590686628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.692342</td>\n",
       "      <td>0.591354</td>\n",
       "      <td>0.893454</td>\n",
       "      <td>0.956525</td>\n",
       "      <td>0.973464</td>\n",
       "      <td>1590690795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.699688</td>\n",
       "      <td>0.594048</td>\n",
       "      <td>0.894302</td>\n",
       "      <td>0.956979</td>\n",
       "      <td>0.977187</td>\n",
       "      <td>1590695100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.693026</td>\n",
       "      <td>0.582585</td>\n",
       "      <td>0.892313</td>\n",
       "      <td>0.955482</td>\n",
       "      <td>0.973328</td>\n",
       "      <td>1590699287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.695578</td>\n",
       "      <td>0.579031</td>\n",
       "      <td>0.892941</td>\n",
       "      <td>0.956231</td>\n",
       "      <td>0.974849</td>\n",
       "      <td>1590703613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  F1 (macro)  F1 (micro)      LRAP      NDCG   timestamp\n",
       "0  0.691742    0.567039    0.892858  0.956125  0.974301  1590686628\n",
       "1  0.692342    0.591354    0.893454  0.956525  0.973464  1590690795\n",
       "2  0.699688    0.594048    0.894302  0.956979  0.977187  1590695100\n",
       "3  0.693026    0.582585    0.892313  0.955482  0.973328  1590699287\n",
       "4  0.695578    0.579031    0.892941  0.956231  0.974849  1590703613"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy      0.694475\n",
      "F1 (macro)    0.582811\n",
      "F1 (micro)    0.893174\n",
      "LRAP          0.956268\n",
      "NDCG          0.974626\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "reset_seed()\n",
    "cross_evaluate(models.split_cnn_bi_lstm_2, model_params={\n",
    "    \"filters_1\": 400, \"filters_2\": 500, \"loss\": \"mean_squared_error\",\n",
    "    \"embedding_matrix_1\": ft_pretrained_embedding_matrix,\n",
    "    \"embedding_matrix_2\": glove_pretrained_embedding_matrix})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
